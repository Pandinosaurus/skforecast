{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "from skforecast.recursive import ForecasterRecursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA T1200 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CPU RAM Free: 12.07 GB\n"
     ]
    }
   ],
   "source": [
    "# Print information abput the GPU and CPU\n",
    "# ==============================================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0) / 1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0) / 1024**3, 1), 'GB')\n",
    "\n",
    "print(f\"CPU RAM Free: {psutil.virtual_memory().available / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Nombre de la GPU: NVIDIA T1200 Laptop GPU\n",
      "Memoria asignada: 0.0 GB\n",
      "Memoria en caché: 0.0 GB\n",
      "RAM libre en CPU: 11.92 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Usando dispositivo:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memoria asignada:\", round(torch.cuda.memory_allocated(0) / 1024**3, 1), 'GB')\n",
    "    print(\"Memoria en caché:\", round(torch.cuda.memory_reserved(0) / 1024**3, 1), 'GB')\n",
    "\n",
    "print(f\"RAM libre en CPU: {psutil.virtual_memory().available / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con GPU: 0.9561\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Separar en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir a DMatrix (estructura optimizada para XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Configuración del modelo con aceleración por GPU\n",
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': 'hist',  # Utiliza la GPU\n",
    "    'eval_metric': 'logloss',\n",
    "    'device': 'cuda',  # Especifica el uso de GPU\n",
    "}\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_prob = bst.predict(dtest)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo con GPU: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 20\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA T1200 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 20 dense feature groups (1.53 MB) transferred to GPU in 0.004244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.355959\n",
      "RMSE: 434.5683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Crear datos sintéticos\n",
    "X, y = make_regression(n_samples=100000, n_features=20, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo con soporte GPU\n",
    "model = LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    device='gpu',                # ← activa el uso de GPU\n",
    "    gpu_platform_id=0,           # ← opcional, si tienes más de una GPU\n",
    "    gpu_device_id=0,             # ← opcional, para seleccionar GPU\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
