{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ximo/GitHub/skforecast'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pyinstrument extension is already loaded. To reload it, use:\n",
      "  %reload_ext pyinstrument\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import skforecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection import bayesian_search_forecaster_multiseries\n",
    "from skforecast.model_selection import backtesting_forecaster_multiseries\n",
    "from skforecast.utils import *\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.preprocessing import series_long_to_dict\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "%load_ext pyinstrument\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information system and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.9\n",
      "scikit-learn version: 1.6.1\n",
      "skforecast version: 0.16.0\n",
      "pandas version: 2.2.3\n",
      "numpy version: 2.0.2\n",
      "scipy version: 1.15.2\n",
      "psutil version: 5.9.0\n",
      "\n",
      "Computer network name: ximo\n",
      "Machine type: x86_64\n",
      "Processor type: x86_64\n",
      "Platform type: Linux-6.8.0-57-generic-x86_64-with-glibc2.39\n",
      "Operating system: Linux\n",
      "Operating system release: 6.8.0-57-generic\n",
      "Operating system version: #59-Ubuntu SMP PREEMPT_DYNAMIC Sat Mar 15 17:40:59 UTC 2025\n",
      "Number of physical cores: 4\n",
      "Number of logical cores: 8\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "# ==============================================================================\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"skforecast version: {skforecast.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scipy version: {scipy.__version__}\")\n",
    "print(f\"psutil version: {psutil.__version__}\")\n",
    "print(\"\")\n",
    "\n",
    "# Computer information\n",
    "# ==============================================================================\n",
    "#Computer network name\n",
    "print(f\"Computer network name: {platform.node()}\")\n",
    "#Machine type\n",
    "print(f\"Machine type: {platform.machine()}\")\n",
    "#Processor type\n",
    "print(f\"Processor type: {platform.processor()}\")\n",
    "#Platform type\n",
    "print(f\"Platform type: {platform.platform()}\")\n",
    "#Operating system\n",
    "print(f\"Operating system: {platform.system()}\")\n",
    "#Operating system release\n",
    "print(f\"Operating system release: {platform.release()}\")\n",
    "#Operating system version\n",
    "print(f\"Operating system version: {platform.version()}\")\n",
    "#Physical cores\n",
    "print(f\"Number of physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "#Logical cores\n",
    "print(f\"Number of logical cores: {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForecasterAutoregMultiSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of dates: 2010-01-01 00:00:00 - 2010-07-27 09:00:00\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_series = 200\n",
    "len_series = (2000, 5000)\n",
    "series_dict = {}\n",
    "rng = np.random.default_rng(321)\n",
    "for i in range(n_series):\n",
    "    n = rng.integers(low=len_series[0], high=len_series[1])\n",
    "    series_dict[f'series_{i}'] = pd.Series(\n",
    "        data = rng.normal(loc=20, scale=5, size=n),\n",
    "        index=pd.date_range(\n",
    "            start='2010-01-01',\n",
    "            periods=n,\n",
    "            freq='h'\n",
    "        ),\n",
    "        name=f'series_{i}'\n",
    "    )\n",
    "\n",
    "exog_dict = {}\n",
    "rng = np.random.default_rng(321)\n",
    "for k in series_dict.keys():\n",
    "    exog = pd.DataFrame(\n",
    "            index=series_dict[k].index\n",
    "            )\n",
    "    exog['day_of_week'] = exog.index.dayofweek\n",
    "    exog['week_of_year'] = exog.index.isocalendar().week.astype(int)\n",
    "    exog['month'] = exog.index.month\n",
    "    exog_dict[k] = exog\n",
    "\n",
    "\n",
    "print(f\"Range of dates: \"\n",
    "    f\"{np.min([series_dict[k].index.min() for k in series_dict.keys()])} - \"\n",
    "    f\"{np.max([series_dict[k].index.max() for k in series_dict.keys()])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "end_train = '2010-06-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor=LGBMRegressor(random_state=8520, verbose=-1),\n",
    "    lags=50,\n",
    "    # transformer_series=StandardScaler(),\n",
    "    # transformer_exog=StandardScaler(),\n",
    "    encoding=\"ordinal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#%%pyinstrument\n",
    "\n",
    "# forecaster.fit(series=series_dict, exog=exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling fit()\n",
    "# ==============================================================================\n",
    "# def funt_to_profile(forecaster, series, exog):\n",
    "#     forecaster.fit(series=series, exog=exog)\n",
    "\n",
    "# %lprun -f forecaster.fit funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 2.04262 s\n",
      "File: /home/ximo/GitHub/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y at line 961\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   961                                               def _create_train_X_y(\n",
      "   962                                                   self,\n",
      "   963                                                   series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "   964                                                   exog: pd.Series | pd.DataFrame | dict[str, pd.Series | pd.DataFrame] | None = None,\n",
      "   965                                                   store_last_window: bool | list[str] = True,\n",
      "   966                                               ) -> tuple[\n",
      "   967                                                   pd.DataFrame,\n",
      "   968                                                   pd.Series,\n",
      "   969                                                   dict[str, pd.Index],\n",
      "   970                                                   list[str],\n",
      "   971                                                   list[str],\n",
      "   972                                                   list[str],\n",
      "   973                                                   list[str],\n",
      "   974                                                   list[str],\n",
      "   975                                                   dict[str, type],\n",
      "   976                                                   dict[str, pd.Series],\n",
      "   977                                               ]:\n",
      "   978                                                   \"\"\"\n",
      "   979                                                   Create training matrices from multiple time series and exogenous\n",
      "   980                                                   variables. See Notes section for more details depending on the type of\n",
      "   981                                                   `series` and `exog`.\n",
      "   982                                                   \n",
      "   983                                                   Parameters\n",
      "   984                                                   ----------\n",
      "   985                                                   series : pandas DataFrame, dict\n",
      "   986                                                       Training time series.\n",
      "   987                                                   exog : pandas Series, pandas DataFrame, dict, default None\n",
      "   988                                                       Exogenous variable/s included as predictor/s.\n",
      "   989                                                   store_last_window : bool, list, default True\n",
      "   990                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "   991                                           \n",
      "   992                                                       - If `True`, last window is stored for all series. \n",
      "   993                                                       - If `list`, last window is stored for the series present in the list.\n",
      "   994                                                       - If `False`, last window is not stored.\n",
      "   995                                           \n",
      "   996                                                   Returns\n",
      "   997                                                   -------\n",
      "   998                                                   X_train : pandas DataFrame\n",
      "   999                                                       Training values (predictors).\n",
      "  1000                                                   y_train : pandas Series\n",
      "  1001                                                       Values of the time series related to each row of `X_train`.\n",
      "  1002                                                   series_indexes : dict\n",
      "  1003                                                       Dictionary with the index of each series.\n",
      "  1004                                                   series_names_in_ : list\n",
      "  1005                                                       Names of the series (levels) provided by the user during training.\n",
      "  1006                                                   X_train_series_names_in_ : list\n",
      "  1007                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1008                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1009                                                       some series are dropped during the training process because of NaNs or\n",
      "  1010                                                       because they are not present in the training period.\n",
      "  1011                                                   exog_names_in_ : list\n",
      "  1012                                                       Names of the exogenous variables used during training.\n",
      "  1013                                                   X_train_window_features_names_out_ : list\n",
      "  1014                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1015                                                       internally for training.\n",
      "  1016                                                   X_train_exog_names_out_ : list\n",
      "  1017                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1018                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1019                                                       some exogenous variables are transformed during the training process.\n",
      "  1020                                                   exog_dtypes_in_ : dict\n",
      "  1021                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1022                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1023                                                   last_window_ : dict\n",
      "  1024                                                       Last window of training data for each series. It stores the values \n",
      "  1025                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1026                                           \n",
      "  1027                                                   Notes\n",
      "  1028                                                   -----\n",
      "  1029                                                   - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n",
      "  1030                                                   DataFrame, each exog is duplicated for each series. Exog must have the\n",
      "  1031                                                   same index as `series` (type, length and frequency).\n",
      "  1032                                                   - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n",
      "  1033                                                   or DataFrames. Each key in `exog` must be a column in `series` and the \n",
      "  1034                                                   values are the exog for each series. Exog must have the same index as \n",
      "  1035                                                   `series` (type, length and frequency).\n",
      "  1036                                                   - If `series` is a dict of pandas Series, `exog` must be a dict of pandas\n",
      "  1037                                                   Series or DataFrames. The keys in `series` and `exog` must be the same.\n",
      "  1038                                                   All series and exog must have a pandas DatetimeIndex with the same \n",
      "  1039                                                   frequency.\n",
      "  1040                                                   \n",
      "  1041                                                   \"\"\"\n",
      "  1042                                           \n",
      "  1043         1   92632378.0    9e+07      4.5          series_dict, series_indexes = check_preprocess_series(series=series)\n",
      "  1044         1       3208.0   3208.0      0.0          input_series_is_dict = isinstance(series, dict)\n",
      "  1045         1      13133.0  13133.0      0.0          series_names_in_ = list(series_dict.keys())\n",
      "  1046                                           \n",
      "  1047         1       2399.0   2399.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1048                                                       raise ValueError(\n",
      "  1049                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1050                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1051                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1052                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1053                                                       )\n",
      "  1054                                           \n",
      "  1055       201     172166.0    856.5      0.0          exog_dict = {serie: None for serie in series_names_in_}\n",
      "  1056         1        632.0    632.0      0.0          exog_names_in_ = None\n",
      "  1057         1        754.0    754.0      0.0          X_train_exog_names_out_ = None\n",
      "  1058         1       1035.0   1035.0      0.0          if exog is not None:\n",
      "  1059         2  146226511.0    7e+07      7.2              exog_dict, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1060         1       1055.0   1055.0      0.0                                              input_series_is_dict = input_series_is_dict,\n",
      "  1061         1        552.0    552.0      0.0                                              series_indexes       = series_indexes,\n",
      "  1062         1        485.0    485.0      0.0                                              series_names_in_     = series_names_in_,\n",
      "  1063         1        473.0    473.0      0.0                                              exog                 = exog,\n",
      "  1064         1        368.0    368.0      0.0                                              exog_dict            = exog_dict\n",
      "  1065                                                                                   )\n",
      "  1066                                           \n",
      "  1067         1       1599.0   1599.0      0.0              if self.is_fitted:\n",
      "  1068                                                           if self.exog_names_in_ is None:\n",
      "  1069                                                               raise ValueError(\n",
      "  1070                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1071                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1072                                                               )\n",
      "  1073                                                           else:\n",
      "  1074                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1075                                                                   raise ValueError(\n",
      "  1076                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1077                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1078                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1079                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1080                                                                   )\n",
      "  1081                                           \n",
      "  1082         1        564.0    564.0      0.0          if not self.is_fitted:\n",
      "  1083         2      79930.0  39965.0      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1084         1       1486.0   1486.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1085         1        311.0    311.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1086         1        531.0    531.0      0.0                                             encoding           = self.encoding,\n",
      "  1087         1       2241.0   2241.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1088                                                                                  )\n",
      "  1089                                                       \n",
      "  1090         2      56807.0  28403.5      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1091         1        220.0    220.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1092         1        487.0    487.0      0.0                                         differentiator   = self.differentiator\n",
      "  1093                                                                              )\n",
      "  1094                                           \n",
      "  1095         2   14978340.0    7e+06      0.7          series_dict, exog_dict = align_series_and_exog_multiseries(\n",
      "  1096         1        336.0    336.0      0.0                                       series_dict          = series_dict,\n",
      "  1097         1        253.0    253.0      0.0                                       input_series_is_dict = input_series_is_dict,\n",
      "  1098         1        234.0    234.0      0.0                                       exog_dict            = exog_dict\n",
      "  1099                                                                            )\n",
      "  1100                                                   \n",
      "  1101         1       2790.0   2790.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1102                                                       self.transformer_series_['_unknown_level'].fit(\n",
      "  1103                                                           np.concatenate(list(series_dict.values())).reshape(-1, 1)\n",
      "  1104                                                       )\n",
      "  1105                                           \n",
      "  1106         1        408.0    408.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1107         2       2796.0   1398.0      0.0          input_matrices = [\n",
      "  1108       200     223719.0   1118.6      0.0              [series_dict[k], exog_dict[k], ignore_exog]\n",
      "  1109       202      90552.0    448.3      0.0               for k in series_dict.keys()\n",
      "  1110                                                   ]\n",
      "  1111                                           \n",
      "  1112         1       2660.0   2660.0      0.0          X_train_autoreg_buffer = []\n",
      "  1113         1       1094.0   1094.0      0.0          X_train_exog_buffer = []\n",
      "  1114         1       1266.0   1266.0      0.0          y_train_buffer = []\n",
      "  1115       201     223105.0   1110.0      0.0          for matrices in input_matrices:\n",
      "  1116                                           \n",
      "  1117       200     242692.0   1213.5      0.0              (\n",
      "  1118       200      57474.0    287.4      0.0                  X_train_autoreg,\n",
      "  1119       200      45637.0    228.2      0.0                  X_train_window_features_names_out_,\n",
      "  1120       200      41151.0    205.8      0.0                  X_train_exog,\n",
      "  1121       200     528038.0   2640.2      0.0                  y_train\n",
      "  1122       400  408764697.0    1e+06     20.0              ) = self._create_train_X_y_single_series(\n",
      "  1123       200     143723.0    718.6      0.0                  y           = matrices[0],\n",
      "  1124       200     291563.0   1457.8      0.0                  exog        = matrices[1],\n",
      "  1125       200     249047.0   1245.2      0.0                  ignore_exog = matrices[2],\n",
      "  1126                                                       )\n",
      "  1127                                           \n",
      "  1128       200     645386.0   3226.9      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1129       200     479970.0   2399.8      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1130       200     277456.0   1387.3      0.0              y_train_buffer.append(y_train)\n",
      "  1131                                           \n",
      "  1132         1  223669522.0    2e+08     11.0          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1133         1   14486290.0    1e+07      0.7          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1134                                           \n",
      "  1135         1       4338.0   4338.0      0.0          if self.is_fitted:\n",
      "  1136                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1137                                                   else:\n",
      "  1138         1  199359724.0    2e+08      9.8              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1139       201     612045.0   3045.0      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1140       200     571197.0   2856.0      0.0                  self.encoding_mapping_[code] = i\n",
      "  1141                                           \n",
      "  1142         3  375142817.0    1e+08     18.4          X_train = pd.concat([\n",
      "  1143         1  283316843.0    3e+08     13.9                        X_train.drop(columns='_level_skforecast'),\n",
      "  1144         1       4566.0   4566.0      0.0                        encoded_values\n",
      "  1145         1       3273.0   3273.0      0.0                    ], axis=1)\n",
      "  1146                                           \n",
      "  1147         1       6556.0   6556.0      0.0          if self.encoding == 'onehot':\n",
      "  1148                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1149         1       3445.0   3445.0      0.0          elif self.encoding == 'ordinal_category':\n",
      "  1150                                                       X_train['_level_skforecast'] = (\n",
      "  1151                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1152                                                       )\n",
      "  1153                                           \n",
      "  1154         1     303365.0 303365.0      0.0          del encoded_values\n",
      "  1155                                           \n",
      "  1156         1       2877.0   2877.0      0.0          exog_dtypes_in_ = None\n",
      "  1157         1       3244.0   3244.0      0.0          if exog is not None:\n",
      "  1158                                           \n",
      "  1159         1   27376447.0    3e+07      1.3              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1160         1      74001.0  74001.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1161                                                           X_train_exog = (\n",
      "  1162                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1163                                                           )\n",
      "  1164                                           \n",
      "  1165         1       7829.0   7829.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1166         1     329289.0 329289.0      0.0              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1167                                           \n",
      "  1168         1      10199.0  10199.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1169         2      28623.0  14311.5      0.0              X_train_exog = transform_dataframe(\n",
      "  1170         1       2813.0   2813.0      0.0                                 df                = X_train_exog,\n",
      "  1171         1       3965.0   3965.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1172         1       2903.0   2903.0      0.0                                 fit               = fit_transformer,\n",
      "  1173         1       2927.0   2927.0      0.0                                 inverse_transform = False\n",
      "  1174                                                                      )\n",
      "  1175                                           \n",
      "  1176         1     445005.0 445005.0      0.0              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1177         1    4005108.0    4e+06      0.2              if not (X_train_exog.index == X_train.index).all():\n",
      "  1178                                                           raise ValueError(\n",
      "  1179                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1180                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1181                                                           )\n",
      "  1182                                           \n",
      "  1183         1      11770.0  11770.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1184         1  144684260.0    1e+08      7.1              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1185                                           \n",
      "  1186         1     868050.0 868050.0      0.0          if y_train.isnull().any():\n",
      "  1187                                                       mask = y_train.notna().to_numpy()\n",
      "  1188                                                       y_train = y_train.iloc[mask]\n",
      "  1189                                                       X_train = X_train.iloc[mask,]\n",
      "  1190                                                       warnings.warn(\n",
      "  1191                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1192                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1193                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1194                                                           \"series with interspersed NaNs.\",\n",
      "  1195                                                           MissingValuesWarning\n",
      "  1196                                                       )\n",
      "  1197                                           \n",
      "  1198         1       7667.0   7667.0      0.0          if self.dropna_from_series:\n",
      "  1199                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1200                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1201                                                           X_train = X_train.iloc[mask, ]\n",
      "  1202                                                           y_train = y_train.iloc[mask]\n",
      "  1203                                                           warnings.warn(\n",
      "  1204                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1205                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1206                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1207                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1208                                                               MissingValuesWarning\n",
      "  1209                                                           )\n",
      "  1210                                                   else:\n",
      "  1211         1   39394444.0    4e+07      1.9              if np.any(X_train.isnull().to_numpy()):\n",
      "  1212                                                           warnings.warn(\n",
      "  1213                                                               \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1214                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1215                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1216                                                               MissingValuesWarning\n",
      "  1217                                                           )\n",
      "  1218                                           \n",
      "  1219         1      59733.0  59733.0      0.0          if X_train.empty:\n",
      "  1220                                                       raise ValueError(\n",
      "  1221                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1222                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1223                                                       )\n",
      "  1224                                                   \n",
      "  1225         1       8269.0   8269.0      0.0          if self.encoding == 'onehot':\n",
      "  1226                                                       X_train_series_names_in_ = [\n",
      "  1227                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1228                                                       ]\n",
      "  1229                                                   else:\n",
      "  1230         1    7533871.0    8e+06      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1231         2      11858.0   5929.0      0.0              X_train_series_names_in_ = [\n",
      "  1232       402    4868002.0  12109.5      0.2                  k for k, v in self.encoding_mapping_.items()\n",
      "  1233       200    2705492.0  13527.5      0.1                  if v in unique_levels\n",
      "  1234                                                       ]\n",
      "  1235                                           \n",
      "  1236                                                   # The last time window of training data is stored so that lags needed as\n",
      "  1237                                                   # predictors in the first iteration of `predict()` can be calculated.\n",
      "  1238         1       5685.0   5685.0      0.0          last_window_ = None\n",
      "  1239         1       5532.0   5532.0      0.0          if store_last_window:\n",
      "  1240                                           \n",
      "  1241         1       5444.0   5444.0      0.0              series_to_store = (\n",
      "  1242         1       6894.0   6894.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1243                                                       )\n",
      "  1244                                           \n",
      "  1245         1      44994.0  44994.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1246         1       7401.0   7401.0      0.0              if series_not_in_series_dict:\n",
      "  1247                                                           warnings.warn(\n",
      "  1248                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1249                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1250                                                               IgnoredArgumentWarning\n",
      "  1251                                                           )\n",
      "  1252                                                           series_to_store = [\n",
      "  1253                                                               s for s in series_to_store \n",
      "  1254                                                               if s not in series_not_in_series_dict\n",
      "  1255                                                           ]\n",
      "  1256                                           \n",
      "  1257         1       6526.0   6526.0      0.0              if series_to_store:\n",
      "  1258         2      12052.0   6026.0      0.0                  last_window_ = {\n",
      "  1259       200   42484091.0 212420.5      2.1                      k: v.iloc[-self.window_size:].copy()\n",
      "  1260       202    1535331.0   7600.6      0.1                      for k, v in series_dict.items()\n",
      "  1261       200    2016171.0  10080.9      0.1                      if k in series_to_store\n",
      "  1262                                                           }\n",
      "  1263                                           \n",
      "  1264         1       3389.0   3389.0      0.0          return (\n",
      "  1265         1       5879.0   5879.0      0.0              X_train,\n",
      "  1266         1       5958.0   5958.0      0.0              y_train,\n",
      "  1267         1       5762.0   5762.0      0.0              series_indexes,\n",
      "  1268         1       5990.0   5990.0      0.0              series_names_in_,\n",
      "  1269         1       5402.0   5402.0      0.0              X_train_series_names_in_,\n",
      "  1270         1       5599.0   5599.0      0.0              exog_names_in_,\n",
      "  1271         1       5532.0   5532.0      0.0              X_train_window_features_names_out_,\n",
      "  1272         1       5760.0   5760.0      0.0              X_train_exog_names_out_,\n",
      "  1273         1       5726.0   5726.0      0.0              exog_dtypes_in_,\n",
      "  1274         1       5527.0   5527.0      0.0              last_window_\n",
      "  1275                                                   )"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling _create_train_X_y()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, series, exog):\n",
    "    forecaster._create_train_X_y(series=series, exog=exog)\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.00374744 s\n",
      "File: /home/ximo/GitHub/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y_single_series at line 836\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   836                                               def _create_train_X_y_single_series(\n",
      "   837                                                   self,\n",
      "   838                                                   y: pd.Series,\n",
      "   839                                                   ignore_exog: bool,\n",
      "   840                                                   exog: pd.DataFrame | None = None\n",
      "   841                                               ) -> tuple[pd.DataFrame, list[str], pd.DataFrame, pd.Series]:\n",
      "   842                                                   \"\"\"\n",
      "   843                                                   Create training matrices from univariate time series and exogenous\n",
      "   844                                                   variables. This method does not transform the exog variables.\n",
      "   845                                                   \n",
      "   846                                                   Parameters\n",
      "   847                                                   ----------\n",
      "   848                                                   y : pandas Series\n",
      "   849                                                       Training time series.\n",
      "   850                                                   ignore_exog : bool\n",
      "   851                                                       If `True`, `exog` is ignored.\n",
      "   852                                                   exog : pandas DataFrame, default None\n",
      "   853                                                       Exogenous variable/s included as predictor/s.\n",
      "   854                                           \n",
      "   855                                                   Returns\n",
      "   856                                                   -------\n",
      "   857                                                   X_train_lags : pandas DataFrame\n",
      "   858                                                       Training values of lags.\n",
      "   859                                                       Shape: (len(y) - self.max_lag, len(self.lags))\n",
      "   860                                                   X_train_window_features_names_out_ : list\n",
      "   861                                                       Names of the window features.\n",
      "   862                                                   X_train_exog : pandas DataFrame\n",
      "   863                                                       Training values of exogenous variables.\n",
      "   864                                                       Shape: (len(y) - self.max_lag, len(exog.columns))\n",
      "   865                                                   y_train : pandas Series\n",
      "   866                                                       Values (target) of the time series related to each row of `X_train`.\n",
      "   867                                                       Shape: (len(y) - self.max_lag, )\n",
      "   868                                                   \n",
      "   869                                                   \"\"\"\n",
      "   870                                           \n",
      "   871         1       9404.0   9404.0      0.3          series_name = y.name\n",
      "   872         1      33924.0  33924.0      0.9          if len(y) <= self.window_size:\n",
      "   873                                                       raise ValueError(\n",
      "   874                                                           f\"Length of '{series_name}' must be greater than the maximum window size \"\n",
      "   875                                                           f\"needed by the forecaster.\\n\"\n",
      "   876                                                           f\"    Length '{series_name}': {len(y)}.\\n\"\n",
      "   877                                                           f\"    Max window size: {self.window_size}.\\n\"\n",
      "   878                                                           f\"    Lags window size: {self.max_lag}.\\n\"\n",
      "   879                                                           f\"    Window features window size: {self.max_size_window_features}.\"\n",
      "   880                                                       )\n",
      "   881                                           \n",
      "   882         1       1712.0   1712.0      0.0          if self.encoding is None:\n",
      "   883                                                       fit_transformer = False\n",
      "   884                                                       transformer_series = self.transformer_series_['_unknown_level']\n",
      "   885                                                   else:\n",
      "   886         1       1830.0   1830.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "   887         1       1389.0   1389.0      0.0              transformer_series = self.transformer_series_[series_name]\n",
      "   888                                           \n",
      "   889         2       9178.0   4589.0      0.2          y = transform_series(\n",
      "   890         1        320.0    320.0      0.0                  series            = y,\n",
      "   891         1        271.0    271.0      0.0                  transformer       = transformer_series,\n",
      "   892         1        332.0    332.0      0.0                  fit               = fit_transformer,\n",
      "   893         1        285.0    285.0      0.0                  inverse_transform = False\n",
      "   894                                                       )\n",
      "   895                                           \n",
      "   896         1      50843.0  50843.0      1.4          y_values = y.to_numpy()\n",
      "   897         1       2190.0   2190.0      0.1          y_index = y.index\n",
      "   898                                           \n",
      "   899         1       1249.0   1249.0      0.0          if self.differentiator_[series_name] is not None:\n",
      "   900                                                       if not self.is_fitted:\n",
      "   901                                                           y_values = self.differentiator_[series_name].fit_transform(y_values)\n",
      "   902                                                       else:\n",
      "   903                                                           differentiator = copy(self.differentiator_[series_name])\n",
      "   904                                                           y_values = differentiator.fit_transform(y_values)\n",
      "   905                                           \n",
      "   906         1        646.0    646.0      0.0          X_train_autoreg = []\n",
      "   907         1     198031.0 198031.0      5.3          train_index = y_index[self.window_size:]\n",
      "   908                                           \n",
      "   909         2    1627902.0 813951.0     43.4          X_train_lags, y_train = self._create_lags(\n",
      "   910         1        399.0    399.0      0.0              y=y_values, X_as_pandas=True, train_index=train_index\n",
      "   911                                                   )\n",
      "   912         1       1276.0   1276.0      0.0          if X_train_lags is not None:\n",
      "   913         1        971.0    971.0      0.0              X_train_autoreg.append(X_train_lags)\n",
      "   914                                                   \n",
      "   915         1        996.0    996.0      0.0          X_train_window_features_names_out_ = None\n",
      "   916         1        986.0    986.0      0.0          if self.window_features is not None:\n",
      "   917                                                       # NOTE: The first `self.differentiation_max` positions of `y_values`\n",
      "   918                                                       # must be removed to match the length of `y_train` after creating\n",
      "   919                                                       # the window features. This is because `y_train` is created using the \n",
      "   920                                                       # global window size of the Forecaster, which includes the maximum \n",
      "   921                                                       # differentiation (self.differentiation_max).\n",
      "   922                                                       n_diff = 0 if self.differentiation is None else self.differentiation_max\n",
      "   923                                                       y_window_features = pd.Series(y_values[n_diff:], index=y_index[n_diff:])\n",
      "   924                                                       X_train_window_features, X_train_window_features_names_out_ = (\n",
      "   925                                                           self._create_window_features(\n",
      "   926                                                               y=y_window_features, X_as_pandas=True, train_index=train_index\n",
      "   927                                                           )\n",
      "   928                                                       )\n",
      "   929                                                       X_train_autoreg.extend(X_train_window_features)\n",
      "   930                                           \n",
      "   931         1       1722.0   1722.0      0.0          if len(X_train_autoreg) == 1:\n",
      "   932         1       1455.0   1455.0      0.0              X_train_autoreg = X_train_autoreg[0]\n",
      "   933                                                   else:\n",
      "   934                                                       X_train_autoreg = pd.concat(X_train_autoreg, axis=1)\n",
      "   935                                                   \n",
      "   936         1    1116318.0    1e+06     29.8          X_train_autoreg['_level_skforecast'] = series_name\n",
      "   937                                           \n",
      "   938         1       1051.0   1051.0      0.0          if ignore_exog:\n",
      "   939                                                       X_train_exog = None\n",
      "   940                                                   else:\n",
      "   941         1        918.0    918.0      0.0              if exog is not None:\n",
      "   942                                                           # The first `self.window_size` positions have to be removed from exog\n",
      "   943                                                           # since they are not in X_train_autoreg.\n",
      "   944         1     454056.0 454056.0     12.1                  X_train_exog = exog.iloc[self.window_size:, ]\n",
      "   945                                                       else:\n",
      "   946                                                           X_train_exog = pd.DataFrame(\n",
      "   947                                                                              data    = np.nan,\n",
      "   948                                                                              columns = ['_dummy_exog_col_to_keep_shape'],\n",
      "   949                                                                              index   = train_index\n",
      "   950                                                                          )\n",
      "   951                                           \n",
      "   952         2     221623.0 110811.5      5.9          y_train = pd.Series(\n",
      "   953         1        398.0    398.0      0.0                        data  = y_train,\n",
      "   954         1        382.0    382.0      0.0                        index = train_index,\n",
      "   955         1        515.0    515.0      0.0                        name  = 'y'\n",
      "   956                                                             )\n",
      "   957                                           \n",
      "   958         1       4871.0   4871.0      0.1          return X_train_autoreg, X_train_window_features_names_out_, X_train_exog, y_train"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling _create_train_X_y_single_series()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, series, exog):\n",
    "    (\n",
    "    X_train_autoreg,\n",
    "    X_train_window_features_names_out_,\n",
    "    X_train_exog,\n",
    "    y_train\n",
    ") = forecaster._create_train_X_y_single_series(\n",
    "        y = series,\n",
    "        exog = exog,\n",
    "        ignore_exog = False,\n",
    "    )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y_single_series funt_to_profile(forecaster, series_dict['series_0'], exog_dict['series_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 36.6131 s\n",
      "File: /home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py\n",
      "Function: predict at line 1537\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1537                                               def predict(\n",
      "  1538                                                   self,\n",
      "  1539                                                   steps: int,\n",
      "  1540                                                   levels: Optional[Union[str, list]]=None,\n",
      "  1541                                                   last_window: Optional[pd.DataFrame]=None,\n",
      "  1542                                                   exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None,\n",
      "  1543                                                   suppress_warnings: bool=False\n",
      "  1544                                               ) -> pd.DataFrame:\n",
      "  1545                                                   \"\"\"\n",
      "  1546                                                   Predict n steps ahead. It is an recursive process in which, each prediction,\n",
      "  1547                                                   is used as a predictor for the next step. Only levels whose last window\n",
      "  1548                                                   ends at the same datetime index can be predicted together.\n",
      "  1549                                           \n",
      "  1550                                                   Parameters\n",
      "  1551                                                   ----------\n",
      "  1552                                                   steps : int\n",
      "  1553                                                       Number of future steps predicted.\n",
      "  1554                                                   levels : str, list, default `None`\n",
      "  1555                                                       Time series to be predicted. If `None` all levels whose last window\n",
      "  1556                                                       ends at the same datetime index will be predicted together.\n",
      "  1557                                                   last_window : pandas DataFrame, default `None`\n",
      "  1558                                                       Series values used to create the predictors (lags) needed in the \n",
      "  1559                                                       first iteration of the prediction (t + 1).\n",
      "  1560                                                       If `last_window = None`, the values stored in `self.last_window` are\n",
      "  1561                                                       used to calculate the initial predictors, and the predictions start\n",
      "  1562                                                       right after training data.\n",
      "  1563                                                   exog : pandas Series, pandas DataFrame, dict, default `None`\n",
      "  1564                                                       Exogenous variable/s included as predictor/s.\n",
      "  1565                                                   suppress_warnings : bool, default `False`\n",
      "  1566                                                       If `True`, skforecast warnings will be suppressed during the prediction \n",
      "  1567                                                       process. See skforecast.exceptions.warn_skforecast_categories for more\n",
      "  1568                                                       information.\n",
      "  1569                                           \n",
      "  1570                                                   Returns\n",
      "  1571                                                   -------\n",
      "  1572                                                   predictions : pandas DataFrame\n",
      "  1573                                                       Predicted values, one column for each level.\n",
      "  1574                                           \n",
      "  1575                                                   \"\"\"\n",
      "  1576                                           \n",
      "  1577         1      60301.0  60301.0      0.0          set_skforecast_warnings(suppress_warnings, action='ignore')\n",
      "  1578                                           \n",
      "  1579         1       1960.0   1960.0      0.0          (\n",
      "  1580         1        710.0    710.0      0.0              last_window_values_dict,\n",
      "  1581         1        360.0    360.0      0.0              exog_values_dict,\n",
      "  1582         1        300.0    300.0      0.0              levels,\n",
      "  1583         1        400.0    400.0      0.0              prediction_index,\n",
      "  1584         1        520.0    520.0      0.0              _\n",
      "  1585         2        2e+10    1e+10     52.8          ) = self._create_predict_inputs(\n",
      "  1586         1        220.0    220.0      0.0              steps       = steps,\n",
      "  1587         1        200.0    200.0      0.0              levels      = levels,\n",
      "  1588         1        210.0    210.0      0.0              last_window = last_window,\n",
      "  1589         1        190.0    190.0      0.0              exog        = exog\n",
      "  1590                                                   )\n",
      "  1591                                           \n",
      "  1592         1        440.0    440.0      0.0          predictions = []\n",
      "  1593      1579     777563.0    492.4      0.0          for level in levels:\n",
      "  1594                                           \n",
      "  1595      3156        2e+10    5e+06     46.0              preds_level = self._recursive_predict(\n",
      "  1596      1578     389436.0    246.8      0.0                                steps       = steps,\n",
      "  1597      1578     382309.0    242.3      0.0                                level       = level,\n",
      "  1598      1578    1154419.0    731.6      0.0                                last_window = last_window_values_dict[level],\n",
      "  1599      1578     973106.0    616.7      0.0                                exog        = exog_values_dict[level]\n",
      "  1600                                                                     )\n",
      "  1601                                                   \n",
      "  1602      1578    1244621.0    788.7      0.0              if self.differentiation is not None:\n",
      "  1603                                                           preds_level = self.differentiator_[level].inverse_transform_next_window(preds_level)\n",
      "  1604                                           \n",
      "  1605      3156  194722123.0  61699.0      0.5              preds_level = pd.Series(\n",
      "  1606      1578     440570.0    279.2      0.0                                data  = preds_level,\n",
      "  1607      1578     483597.0    306.5      0.0                                index = prediction_index,\n",
      "  1608      1578     387574.0    245.6      0.0                                name  = level\n",
      "  1609                                                                     )\n",
      "  1610                                           \n",
      "  1611      3156    4344345.0   1376.5      0.0              preds_level = transform_series(\n",
      "  1612      1578     472086.0    299.2      0.0                                series            = preds_level,\n",
      "  1613      1578    1646270.0   1043.3      0.0                                transformer       = self.transformer_series_[level],\n",
      "  1614      1578     440865.0    279.4      0.0                                fit               = False,\n",
      "  1615      1578     386664.0    245.0      0.0                                inverse_transform = True\n",
      "  1616                                                                     )\n",
      "  1617                                           \n",
      "  1618      1578    1421995.0    901.1      0.0              predictions.append(preds_level)\n",
      "  1619                                           \n",
      "  1620         1  228002906.0    2e+08      0.6          predictions = pd.concat(predictions, axis=1)\n",
      "  1621                                                   \n",
      "  1622         1      68061.0  68061.0      0.0          set_skforecast_warnings(suppress_warnings, action='default')\n",
      "  1623                                           \n",
      "  1624         1        240.0    240.0      0.0          return predictions"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling predict()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, steps, exog):\n",
    "    forecaster.predict(steps=steps, exog=exog, suppress_warnings=True)\n",
    "\n",
    "%lprun -f forecaster.predict funt_to_profile(forecaster, 7, exog_dict_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Functions to profile:\n",
    "# ==============================================================================\n",
    "# check_preprocess_exog_multiseries\n",
    "# align_series_and_exog_multiseries\n",
    "# _create_train_X_y_single_series\n",
    "# _create_predict_inputs\n",
    "# _recursive_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling align_series_and_exog_multiseries()\n",
    "# ==============================================================================\n",
    "# def funt_to_profile(series_dict, input_series_is_dict, exog_dict):\n",
    "#     align_series_and_exog_multiseries(\n",
    "#         series_dict=series_dict,\n",
    "#         input_series_is_dict=input_series_is_dict,\n",
    "#         exog_dict = exog_dict,\n",
    "#     )\n",
    "\n",
    "# %lprun -f align_series_and_exog_multiseries funt_to_profile(series_dict_train, True, exog_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Profiling check_preprocess_exog_multiseries()\n",
    "# # ==============================================================================\n",
    "# series_indexes = {k: v.index for k, v  in series_dict_train.items()}\n",
    "# series_col_names = list(series_dict_train.keys())\n",
    "\n",
    "# def funt_to_profile(input_series_is_dict, series_indexes, series_col_names, exog, exog_dict):\n",
    "#     check_preprocess_exog_multiseries(\n",
    "#         input_series_is_dict = input_series_is_dict,\n",
    "#         series_indexes = series_indexes,\n",
    "#         series_col_names = series_col_names,\n",
    "#         exog = exog_dict_train,\n",
    "#         exog_dict = exog_dict_train,\n",
    "#     )\n",
    "\n",
    "# %lprun -f check_preprocess_exog_multiseries funt_to_profile(True, series_indexes, series_col_names, exog, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original code execution time: 0.00015878677368164062 seconds\n",
      "Optimized code 1 execution time: 0.00017976760864257812 seconds\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def fun_original():\n",
    "    pass\n",
    "\n",
    "def fun_optimized_1():\n",
    "    pass\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    fun_original()\n",
    "except TypeError as e:\n",
    "    end_time = time.time()\n",
    "    print(e)\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "print(f\"Original code execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    fun_optimized_1()\n",
    "except TypeError as e:\n",
    "    end_time = time.time()\n",
    "    print(e)\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "print(f\"Optimized code 1 execution time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn OrdinalEncoder time: 0.0176 seconds\n",
      "FastOrdinalEncoder time: 0.0072 seconds\n",
      "UltraFastOrdinalEncoder time: 0.0053 seconds\n",
      "All encoders produced the same results.\n",
      "Inverse transform works correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Fast Ordinal Encoder implementation\n",
    "class FastOrdinalEncoder:\n",
    "    def __init__(self):\n",
    "        self.category_map = None\n",
    "        self.inverse_category_map = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Fit the encoder to the unique categories in the data.\"\"\"\n",
    "        unique_categories = np.unique(data)\n",
    "        self.category_map = {category: idx for idx, category in enumerate(unique_categories)}\n",
    "        self.inverse_category_map = {idx: category for idx, category in enumerate(unique_categories)}\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transform the data to ordinal values.\"\"\"\n",
    "        return np.vectorize(self.category_map.get)(data)\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit and transform the data.\"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def inverse_transform(self, encoded_data):\n",
    "        \"\"\"Inverse transform the encoded data back to original categories.\"\"\"\n",
    "        return np.vectorize(self.inverse_category_map.get)(encoded_data)\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class UltraFastOrdinalEncoder:\n",
    "    \"\"\"\n",
    "    Encode categorical features as an integer array. The input to this transformer should\n",
    "    be an array-like of integers or strings, denoting the values taken on by categorical\n",
    "    (discrete) features. The features are converted to ordinal integers. This results in\n",
    "    a single column of integers (0 to n_categories - 1) per feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : np.ndarray\n",
    "        Unique categories in the data.\n",
    "    category_map_ : dict\n",
    "        Mapping of categories to integers.\n",
    "    inverse_category_map_ : dict\n",
    "        Mapping of integers to categories.\n",
    "    unknown_value : int | float, default=-1\n",
    "        Value to use for unknown categories.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, unknown_value: int | float = -1):\n",
    "\n",
    "        self.unknown_value = unknown_value\n",
    "        self.categories_ = None\n",
    "        self.category_map_ = None\n",
    "        self.inverse_category_map_ = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray | pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Fit the encoder to the unique categories in the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Input data to fit the encoder.\n",
    "        \"\"\"\n",
    "\n",
    "        self.categories_ = np.unique(X)\n",
    "        self.category_map_ = {category: idx for idx, category in enumerate(self.categories_)}\n",
    "        self.inverse_category_map_ = {idx: category for idx, category in enumerate(self.categories_)}\n",
    "    \n",
    "    def transform(self, X: np.ndarray | pd.Series) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform the data to ordinal values using direct indexing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Input data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Transformed data with ordinal values.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.categories_ is None:\n",
    "            raise ValueError(\"The encoder has not been fitted yet. Call 'fit' before 'transform'.\")\n",
    "        if not isinstance(X, (np.ndarray, pd.Series)):\n",
    "            raise ValueError(\"Input data must be a numpy array or pandas Series.\")\n",
    "        \n",
    "        # encoded_data = np.searchsorted(self.categories_, X, side='right')\n",
    "        # encoded_data[encoded_data == len(self.categories_)] = self.unknown_value  # Handle unknown values\n",
    "\n",
    "        # encoded_data = np.array([\n",
    "        #     self.category_map_.get(x, self.unknown_value) for x in X\n",
    "        # ])\n",
    "\n",
    "        encoded_data = pd.Series(X).map(self.category_map_).fillna(self.unknown_value).to_numpy()\n",
    "\n",
    "        return encoded_data\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray | pd.Series) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fit encoder and transform the data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Input data to fit and transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Transformed data with ordinal values.\n",
    "        \"\"\"\n",
    "\n",
    "        self.fit(X)\n",
    "        \n",
    "        return self.transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X: np.ndarray | pd.Series) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Inverse transform the encoded data back to original categories.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Encoded data to inverse transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Inverse transformed data with original categories.\n",
    "        \"\"\"\n",
    "        if self.categories_ is None:\n",
    "            raise ValueError(\"The encoder has not been fitted yet. Call 'fit' before 'inverse_transform'.\")\n",
    "        if not isinstance(X, (np.ndarray, pd.Series)):\n",
    "            raise ValueError(\"Input data must be a numpy array or pandas Series.\")\n",
    "        \n",
    "        # inverse_encoded_data = np.array([\n",
    "        #     self.inverse_category_map_.get(x, self.unknown_value) for x in X\n",
    "        # ])\n",
    "        inverse_encoded_data = pd.Series(X).map(self.inverse_category_map_).fillna(self.unknown_value).to_numpy()\n",
    "\n",
    "        return inverse_encoded_data\n",
    "\n",
    "\n",
    "# Create a large synthetic dataset of strings (categories)\n",
    "np.random.seed(42)\n",
    "categories = ['red', 'green', 'blue', 'yellow', 'purple', 'orange', 'pink']\n",
    "data = np.random.choice(categories, size=10_000)\n",
    "\n",
    "# Benchmark sklearn OrdinalEncoder\n",
    "start_time = time.time()\n",
    "sklearn_encoder = OrdinalEncoder()\n",
    "sklearn_encoded_data = sklearn_encoder.fit_transform(data.reshape(-1, 1))\n",
    "sklearn_time = time.time() - start_time\n",
    "print(f\"Sklearn OrdinalEncoder time: {sklearn_time:.4f} seconds\")\n",
    "\n",
    "# Benchmark FastOrdinalEncoder\n",
    "start_time = time.time()\n",
    "fast_encoder = FastOrdinalEncoder()\n",
    "fast_encoded_data = fast_encoder.fit_transform(data)\n",
    "fast_time = time.time() - start_time\n",
    "print(f\"FastOrdinalEncoder time: {fast_time:.4f} seconds\")\n",
    "\n",
    "# Benchmark UltraFastOrdinalEncoder\n",
    "start_time = time.time()\n",
    "ultra_fast_encoder = UltraFastOrdinalEncoder()\n",
    "ultra_fast_encoded_data = ultra_fast_encoder.fit_transform(data)\n",
    "ultra_fast_time = time.time() - start_time\n",
    "print(f\"UltraFastOrdinalEncoder time: {ultra_fast_time:.4f} seconds\")\n",
    "\n",
    "# Check if the results are the same\n",
    "assert np.array_equal(sklearn_encoded_data.flatten(), fast_encoded_data)\n",
    "assert np.array_equal(sklearn_encoded_data.flatten(), ultra_fast_encoded_data)\n",
    "print(\"All encoders produced the same results.\")\n",
    "\n",
    "# check inverse transform\n",
    "assert np.array_equal(data, fast_encoder.inverse_transform(fast_encoded_data))\n",
    "assert np.array_equal(data, ultra_fast_encoder.inverse_transform(ultra_fast_encoded_data))\n",
    "print(\"Inverse transform works correctly.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_16_p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
