{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_weights(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 0 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), 0, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_2(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 2 if index is between '2022-01-11' and '2022-01-13', 3 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-11\") & (index <= \"2022-01-13\"), 2, 3)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_nan(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return np.nan if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), np.nan, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_negative(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return -1 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), -1, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "series = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.12362923, 0.51328688],\n",
    "            [0.65138268, 0.11599708],\n",
    "            [0.58142898, 0.72350895],\n",
    "            [0.72969992, 0.10305721],\n",
    "            [0.97790567, 0.20581485],\n",
    "            [0.56924731, 0.41262027],\n",
    "            [0.85369084, 0.82107767],\n",
    "            [0.75425194, 0.0107816],\n",
    "            [0.08167939, 0.94951918],\n",
    "            [0.00249297, 0.55583355],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-04\",\n",
    "            \"2022-01-05\",\n",
    "            \"2022-01-06\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=\"D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_onehot = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 0.0, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 0.0, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 0.0, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category = X_train_ordinal.copy()\n",
    "X_train_ordinal_category[\"_level_skforecast\"] = X_train_ordinal_category[\n",
    "    \"_level_skforecast\"\n",
    "].astype(\"category\")\n",
    "\n",
    "X_train_onehot_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category_diferent_length = X_train_ordinal_diferent_length.copy()\n",
    "X_train_ordinal_category_diferent_length[\"_level_skforecast\"] = (\n",
    "    X_train_ordinal_category_diferent_length[\"_level_skforecast\"].astype(\"category\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"weight_func, expected\",\n",
    "    [\n",
    "        (\n",
    "            {\"series_1\": custom_weights},\n",
    "            np.array(\n",
    "                [\n",
    "                    1.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_2\": custom_weights_2},\n",
    "            np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0]),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_1\": custom_weights, \"series_2\": custom_weights_2},\n",
    "            np.array([1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2]),\n",
    "        ),\n",
    "    ],\n",
    "    ids=lambda values: f\"levels: {values}\",\n",
    ")\n",
    "def test_create_sample_weights_output_using_weight_func_dict_different_series_lengths(\n",
    "    weight_func, expected\n",
    "):\n",
    "    \"\"\"\n",
    "    Test `sample_weights` creation using `weight_func` with series of different lengths.\n",
    "    \"\"\"\n",
    "    forecaster = ForecasterRecursiveMultiSeries(\n",
    "                     regressor          = LinearRegression(),\n",
    "                     lags               = 3,\n",
    "                     encoding           = \"ordinal\",\n",
    "                     transformer_series = StandardScaler(),\n",
    "                     weight_func        = weight_func\n",
    "                 )\n",
    "    forecaster.encoding_mapping_ = {\"series_1\": 0, \"series_2\": 1}\n",
    "    results = forecaster.create_sample_weights(\n",
    "        series_names_in_=[\"series_1\", \"series_2\"],\n",
    "        X_train=X_train_ordinal_diferent_length,\n",
    "    )\n",
    "\n",
    "    assert np.array_equal(results, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.DataFrame({'l1': pd.Series(np.arange(10)), \n",
    "                       'l2': pd.Series(np.arange(10))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3187: UnknownLevelWarning: As `encoding` is set to `None`, no distinction between levels is made. All residuals are stored in the '_unknown_level' key. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=UnknownLevelWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'l1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     34\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mset_out_sample_residuals(\n\u001b[1;32m     35\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true,\n\u001b[1;32m     36\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m], y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m---> 40\u001b[0m y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_series_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     41\u001b[0m y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mtransformer_series_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     42\u001b[0m y_pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mtransformer_series_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(y_pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'l1'"
     ]
    }
   ],
   "source": [
    "series_train = {\n",
    "    'l1': pd.Series(\n",
    "        np.array([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331,\n",
    "                    -0.74088465, -1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,\n",
    "                    2.34740965,  0.96849691, -0.75938718,  0.90219827, -0.46695317,\n",
    "                    -0.06068952,  0.78884434, -1.25666813,  0.57585751,  1.39897899]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    ),\n",
    "    'l2': pd.Series(\n",
    "        np.array([1.32229806, -0.29969852,  0.90291934, -1.62158273, -0.15818926,\n",
    "                    0.44948393, -1.34360107, -0.08168759,  1.72473993,  2.61815943,\n",
    "                    0.77736134,  0.8286332 , -0.95898831, -1.20938829, -1.41229201,\n",
    "                    0.54154683,  0.7519394 , -0.65876032, -1.22867499,  0.25755777]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    )\n",
    "}\n",
    "y_true  = {\n",
    "    'l1': np.array([ 0.31290292, -0.13081169,  1.26998312, -0.09296246, -0.06615089]),\n",
    "    'l2': np.array([-1.10821447,  0.13595685,  1.34707776,  0.06114402,  0.0709146 ])\n",
    "}\n",
    "y_pred = {\n",
    "    'l1': np.array([0.43365454, 0.27748366, 0.53025239, 0.53672097, 0.61835001]),\n",
    "    'l2': np.array([-0.79501746,  0.30003095, -1.60270159,  0.26679883, -1.26162378])\n",
    "}\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    regressor          = LinearRegression(),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                    differentiation    = 1,\n",
    "                    encoding=None\n",
    "                )\n",
    "forecaster.fit(series=series_train)\n",
    "forecaster.set_out_sample_residuals(\n",
    "    y_true = y_true,\n",
    "    y_pred = y_pred\n",
    ")\n",
    "\n",
    "y_true['_unknown_level'] = np.concatenate([y_true['l2'], y_true['l1']])\n",
    "y_true['l1'] = forecaster.transformer_series_['l1'].transform(y_true['l1'].reshape(-1, 1)).flatten()\n",
    "y_true['l2'] = forecaster.transformer_series_['l2'].transform(y_true['l2'].reshape(-1, 1)).flatten()\n",
    "y_pred['l1'] = forecaster.transformer_series_['l1'].transform(y_pred['l1'].reshape(-1, 1)).flatten()\n",
    "y_pred['l2'] = forecaster.transformer_series_['l2'].transform(y_pred['l2'].reshape(-1, 1)).flatten()\n",
    "y_true['_unknown_level'] = forecaster.transformer_series_['_unknown_level'].transform(y_true['_unknown_level'].reshape(-1, 1)).flatten()\n",
    "y_true['l1'] = forecaster.differentiator_['l1'].transform(y_true['l1'])[forecaster.differentiation_max:]\n",
    "y_true['l2'] = forecaster.differentiator_['l2'].transform(y_true['l2'])[forecaster.differentiation_max:]\n",
    "y_pred['l1'] = forecaster.differentiator_['l1'].transform(y_pred['l1'])[forecaster.differentiation_max:]\n",
    "y_pred['l2'] = forecaster.differentiator_['l2'].transform(y_pred['l2'])[forecaster.differentiation_max:]\n",
    "y_true['_unknown_level'] = forecaster.differentiator_['_unknown_level'].transform(y_true['_unknown_level'])[forecaster.differentiation_max:]\n",
    "residuals = {}\n",
    "residuals['l1'] = y_true['l1'] - y_pred['l1']\n",
    "residuals['l2'] = y_true['l2'] - y_pred['l2']\n",
    "residuals['_unknown_level'] = y_true['_unknown_level'] - np.concatenate([y_pred['l2'], y_pred['l1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: l1\n",
      "key: l2\n"
     ]
    }
   ],
   "source": [
    "for key in residuals.keys():\n",
    "    print(f\"key: {key}\")\n",
    "    np.testing.assert_array_almost_equal(residuals[key], forecaster.out_sample_residuals_[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6845009 , -0.62968343, -0.40829535, -0.31319701, -0.20565481,\n",
       "       -0.1640741 , -0.12075162,  0.73973073,  1.33253838,  2.94977935])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.concatenate([(y_true['l2'] - y_pred['l2']), (y_true['l1'] - y_pred['l1'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l1'] - y_pred['l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l2'] - y_pred['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838,\n",
       "       -0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals['_unknown_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3187: UnknownLevelWarning: As `encoding` is set to `None`, no distinction between levels is made. All residuals are stored in the '_unknown_level' key. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=UnknownLevelWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_unknown_level': {0: array([2.8008002 , 1.38354995]),\n",
       "  4: array([-0.25863534, -1.23173923, -0.04930636]),\n",
       "  5: array([1.03260854]),\n",
       "  8: array([0.13413074]),\n",
       "  9: array([-2.83820057])}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_train = {\n",
    "    'l1': pd.Series(\n",
    "        np.array([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331,\n",
    "                    -0.74088465, -1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,\n",
    "                    2.34740965,  0.96849691, -0.75938718,  0.90219827, -0.46695317,\n",
    "                    -0.06068952,  0.78884434, -1.25666813,  0.57585751,  1.39897899]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    ),\n",
    "    'l2': pd.Series(\n",
    "        np.array([1.32229806, -0.29969852,  0.90291934, -1.62158273, -0.15818926,\n",
    "                    0.44948393, -1.34360107, -0.08168759,  1.72473993,  2.61815943,\n",
    "                    0.77736134,  0.8286332 , -0.95898831, -1.20938829, -1.41229201,\n",
    "                    0.54154683,  0.7519394 , -0.65876032, -1.22867499,  0.25755777]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    )\n",
    "}\n",
    "y_true  = {\n",
    "    'l1': np.array([ 0.31290292, -0.13081169,  1.26998312, -0.09296246, -0.06615089]),\n",
    "    'l2': np.array([-1.10821447,  0.13595685,  1.34707776,  0.06114402,  0.0709146 ])\n",
    "}\n",
    "y_pred = {\n",
    "    'l1': np.array([0.43365454, 0.27748366, 0.53025239, 0.53672097, 0.61835001]),\n",
    "    'l2': np.array([-0.79501746,  0.30003095, -1.60270159,  0.26679883, -1.26162378])\n",
    "}\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    regressor          = LinearRegression(),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                    differentiation    =1,\n",
    "                    encoding           = None\n",
    "                )\n",
    "forecaster.fit(series=series_train)\n",
    "forecaster.set_out_sample_residuals(\n",
    "    y_true = y_true,\n",
    "    y_pred = y_pred\n",
    ")\n",
    "\n",
    "forecaster.out_sample_residuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m outsample_residuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m residuals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      4\u001b[0m outsample_residuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m----> 5\u001b[0m     [\u001b[43moutsample_residuals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, residuals]\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m outsample_residuals\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "outsample_residuals = np.array([2,3])\n",
    "residuals = [2,3]\n",
    "\n",
    "outsample_residuals = np.concatenate(\n",
    "    [outsample_residuals or np.array([]), residuals]\n",
    ")\n",
    "line 5ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:460: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3348: UserWarning: The following bins of level l1 have no out of sample residuals: [3, 5, 6, 8, 9]. No predicted values fall in the interval [(4.8, 5.4), (6.0, 6.6), (6.6, 7.199999999999999), (7.800000000000001, 8.4), (8.4, 9.0)]. Empty bins will be filled with a random sample of residuals.\n",
      "  f\"The following bins of level {level} have no out of sample residuals: \"\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3348: UserWarning: The following bins of level l2 have no out of sample residuals: [3, 5, 6, 8, 9]. No predicted values fall in the interval [(4.8, 5.4), (6.0, 6.6), (6.6, 7.199999999999999), (7.800000000000001, 8.4), (8.4, 9.0)]. Empty bins will be filled with a random sample of residuals.\n",
      "  f\"The following bins of level {level} have no out of sample residuals: \"\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3187: UnknownLevelWarning: As `encoding` is set to `None`, no distinction between levels is made. All residuals are stored in the '_unknown_level' key. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=UnknownLevelWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m])}\n\u001b[1;32m     10\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mset_out_sample_residuals(y_true\u001b[38;5;241m=\u001b[39my_true, y_pred\u001b[38;5;241m=\u001b[39my_pred)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_out_sample_residuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mout_sample_residuals_\n\u001b[1;32m     14\u001b[0m expected \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m), \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m }\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3174\u001b[0m, in \u001b[0;36mForecasterRecursiveMultiSeries.set_out_sample_residuals\u001b[0;34m(self, y_true, y_pred, append, random_state)\u001b[0m\n\u001b[1;32m   3167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided keys in `y_pred` and `y_true` do not match any series \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseen during `fit`. Residuals cannot be updated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3170\u001b[0m     )\n\u001b[1;32m   3172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m series_to_update:\n\u001b[1;32m   3173\u001b[0m     residuals_level, residuals_by_bin_level \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 3174\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binning_out_sample_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m            \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   3180\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3181\u001b[0m     )\n\u001b[1;32m   3182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_sample_residuals_[level] \u001b[38;5;241m=\u001b[39m residuals_level\n\u001b[1;32m   3183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_sample_residuals_by_bin_[level] \u001b[38;5;241m=\u001b[39m residuals_by_bin_level\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3325\u001b[0m, in \u001b[0;36mForecasterRecursiveMultiSeries._binning_out_sample_residuals\u001b[0;34m(self, level, y_true, y_pred, append, random_state)\u001b[0m\n\u001b[1;32m   3321\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3322\u001b[0m             outsample_residuals_by_bin[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m   3324\u001b[0m     outsample_residuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m-> 3325\u001b[0m                             [\u001b[43moutsample_residuals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, residuals]\n\u001b[1;32m   3326\u001b[0m                           )\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3328\u001b[0m     outsample_residuals_by_bin \u001b[38;5;241m=\u001b[39m residuals_by_bin\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                LinearRegression(),\n",
    "                lags=3,\n",
    "                encoding='ordinal',\n",
    "                )\n",
    "forecaster.fit(series=series)\n",
    "y_true = {'l1': np.array([1, 2, 3, 4, 5]), 'l2': np.array([2, 3, 4, 5, 6])}\n",
    "y_pred = {'l1': np.array([0, 1, 2, 3, 4]), 'l2': np.array([0, 1, 2, 3, 4])}\n",
    "\n",
    "forecaster.set_out_sample_residuals(y_true=y_true, y_pred=y_pred)\n",
    "forecaster.set_out_sample_residuals(y_true=y_true, y_pred=y_pred, append=True)\n",
    "results = forecaster.out_sample_residuals_\n",
    "\n",
    "expected = {\n",
    "    'l1': np.array([1, 1, 1, 1, 1] * 2), \n",
    "    'l2': np.array([2, 2, 2, 2, 2] * 2),\n",
    "    '_unknown_level': np.array([2, 2, 2, 2, 2, 1, 1, 1, 1, 1] * 2)\n",
    "}\n",
    "\n",
    "assert expected.keys() == results.keys()\n",
    "for k in results.keys():\n",
    "    np.testing.assert_array_almost_equal(np.sort(expected[k]), np.sort(results[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:460: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                LinearRegression(),\n",
    "                lags=3,\n",
    "                encoding='ordinal',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.out_sample_residuals_by_bin_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.differentiator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.out_sample_residuals_by_bin_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:460: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3352: UserWarning: The following bins of level _unknown_level have no out of sample residuals: [3, 5, 6, 8, 9]. No predicted values fall in the interval [(4.9, 5.2), (6.0, 6.8), (6.8, 7.1), (8.0, 8.700000000000001), (8.700000000000001, 9.0)]. Empty bins will be filled with a random sample of residuals.\n",
      "  if empty_bins:\n"
     ]
    }
   ],
   "source": [
    "encoding = None\n",
    "forecaster = ForecasterRecursiveMultiSeries(LinearRegression(), lags=3, encoding=encoding)\n",
    "forecaster.fit(series=series)\n",
    "y_true = {'_unknown_level': np.array([1, 2, 3, 5, 6])}\n",
    "y_pred = {'_unknown_level': np.array([0, 1, 2, 3, 4])}\n",
    "\n",
    "forecaster.set_out_sample_residuals(y_true=y_true, y_pred=y_pred)\n",
    "results = forecaster.out_sample_residuals_\n",
    "\n",
    "if encoding is None:\n",
    "    expected = {\n",
    "        '_unknown_level': np.array([1, 1, 1, 2, 2])\n",
    "    }\n",
    "else:\n",
    "    expected = {\n",
    "        'l1': None,\n",
    "        'l2': None,\n",
    "        '_unknown_level': np.array([1, 1, 1, 2, 2])\n",
    "    }\n",
    "\n",
    "assert expected.keys() == results.keys()\n",
    "for k in results.keys():\n",
    "    if results[k] is None:\n",
    "        assert results[k] == expected[k]\n",
    "    else:\n",
    "        np.testing.assert_array_almost_equal(expected[k], results[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({\"l1\": 124}.keys()) == [\"l1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'l2': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " '_unknown_level': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': array([1, 1, 1, 1, 1]), 'l4': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_14_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
