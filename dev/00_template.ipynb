{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/ubuntu/varios/skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_weights(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 0 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), 0, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_2(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 2 if index is between '2022-01-11' and '2022-01-13', 3 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-11\") & (index <= \"2022-01-13\"), 2, 3)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_nan(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return np.nan if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), np.nan, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_negative(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return -1 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), -1, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "series = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.12362923, 0.51328688],\n",
    "            [0.65138268, 0.11599708],\n",
    "            [0.58142898, 0.72350895],\n",
    "            [0.72969992, 0.10305721],\n",
    "            [0.97790567, 0.20581485],\n",
    "            [0.56924731, 0.41262027],\n",
    "            [0.85369084, 0.82107767],\n",
    "            [0.75425194, 0.0107816],\n",
    "            [0.08167939, 0.94951918],\n",
    "            [0.00249297, 0.55583355],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-04\",\n",
    "            \"2022-01-05\",\n",
    "            \"2022-01-06\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=\"D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_onehot = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 0.0, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 0.0, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 0.0, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category = X_train_ordinal.copy()\n",
    "X_train_ordinal_category[\"_level_skforecast\"] = X_train_ordinal_category[\n",
    "    \"_level_skforecast\"\n",
    "].astype(\"category\")\n",
    "\n",
    "X_train_onehot_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category_diferent_length = X_train_ordinal_diferent_length.copy()\n",
    "X_train_ordinal_category_diferent_length[\"_level_skforecast\"] = (\n",
    "    X_train_ordinal_category_diferent_length[\"_level_skforecast\"].astype(\"category\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"weight_func, expected\",\n",
    "    [\n",
    "        (\n",
    "            {\"series_1\": custom_weights},\n",
    "            np.array(\n",
    "                [\n",
    "                    1.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_2\": custom_weights_2},\n",
    "            np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0]),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_1\": custom_weights, \"series_2\": custom_weights_2},\n",
    "            np.array([1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2]),\n",
    "        ),\n",
    "    ],\n",
    "    ids=lambda values: f\"levels: {values}\",\n",
    ")\n",
    "def test_create_sample_weights_output_using_weight_func_dict_different_series_lengths(\n",
    "    weight_func, expected\n",
    "):\n",
    "    \"\"\"\n",
    "    Test `sample_weights` creation using `weight_func` with series of different lengths.\n",
    "    \"\"\"\n",
    "    forecaster = ForecasterRecursiveMultiSeries(\n",
    "                     regressor          = LinearRegression(),\n",
    "                     lags               = 3,\n",
    "                     encoding           = \"ordinal\",\n",
    "                     transformer_series = StandardScaler(),\n",
    "                     weight_func        = weight_func\n",
    "                 )\n",
    "    forecaster.encoding_mapping_ = {\"series_1\": 0, \"series_2\": 1}\n",
    "    results = forecaster.create_sample_weights(\n",
    "        series_names_in_=[\"series_1\", \"series_2\"],\n",
    "        X_train=X_train_ordinal_diferent_length,\n",
    "    )\n",
    "\n",
    "    assert np.array_equal(results, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.DataFrame({'l1': pd.Series(np.arange(10)), \n",
    "                       'l2': pd.Series(np.arange(10))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['l1', 'l2'])\n",
      "dict_keys(['l1', 'l2'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3328: UserWarning: The following bins of level l1 have no out of sample residuals: [0, 1, 2, 3, 6, 7, 8, 9]. No predicted values fall in the interval [(-1.5464242751012143, -1.1343836865702515), (-1.1343836865702515, -0.6089330546394245), (-0.6089330546394245, -0.4962003465146826), (-0.4962003465146826, -0.4446154660658918), (0.3793469193722755, 0.7804383700118647), (0.7804383700118647, 1.1779744087861057), (1.1779744087861057, 1.4664504326276242), (1.4664504326276242, 1.936395796101717)]. Empty bins will be filled with a random sample of residuals.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3328: UserWarning: The following bins of level l2 have no out of sample residuals: [1, 2, 3, 4, 5, 6, 7, 8]. No predicted values fall in the interval [(-1.0939572822957513, -0.7264532512956374), (-0.7264532512956374, -0.33667815394783107), (-0.33667815394783107, -0.055942461951200805), (-0.055942461951200805, 0.17559293527501285), (0.17559293527501285, 0.33958425442601686), (0.33958425442601686, 0.3905821207518044), (0.3905821207518044, 0.6225559335263092), (0.6225559335263092, 0.8890993499573805)]. Empty bins will be filled with a random sample of residuals.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/varios/skforecast/skforecast/recursive/_forecaster_recursive_multiseries.py:3328: UserWarning: The following bins of level _unknown_level have no out of sample residuals: [1, 2, 3, 6, 7]. No predicted values fall in the interval [(-1.2651465559442892, -0.689085683881688), (-0.689085683881688, -0.4873706979342976), (-0.4873706979342976, -0.29729427965427824), (0.36209408328555953, 0.4511136791531289), (0.4511136791531289, 0.8862398307032882)]. Empty bins will be filled with a random sample of residuals.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/skforecast_14_py12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/skforecast_14_py12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/skforecast_14_py12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/skforecast_14_py12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "series_train = {\n",
    "    'l1': pd.Series(\n",
    "        np.array([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331,\n",
    "                    -0.74088465, -1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,\n",
    "                    2.34740965,  0.96849691, -0.75938718,  0.90219827, -0.46695317,\n",
    "                    -0.06068952,  0.78884434, -1.25666813,  0.57585751,  1.39897899]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    ),\n",
    "    'l2': pd.Series(\n",
    "        np.array([1.32229806, -0.29969852,  0.90291934, -1.62158273, -0.15818926,\n",
    "                    0.44948393, -1.34360107, -0.08168759,  1.72473993,  2.61815943,\n",
    "                    0.77736134,  0.8286332 , -0.95898831, -1.20938829, -1.41229201,\n",
    "                    0.54154683,  0.7519394 , -0.65876032, -1.22867499,  0.25755777]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    )\n",
    "}\n",
    "y_true  = {\n",
    "    'l1': np.array([ 0.31290292, -0.13081169,  1.26998312, -0.09296246, -0.06615089]),\n",
    "    'l2': np.array([-1.10821447,  0.13595685,  1.34707776,  0.06114402,  0.0709146 ])\n",
    "}\n",
    "y_pred = {\n",
    "    'l1': np.array([0.43365454, 0.27748366, 0.53025239, 0.53672097, 0.61835001]),\n",
    "    'l2': np.array([-0.79501746,  0.30003095, -1.60270159,  0.26679883, -1.26162378])\n",
    "}\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    regressor          = LinearRegression(),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                    differentiation    = 1\n",
    "                )\n",
    "forecaster.fit(series=series_train)\n",
    "forecaster.set_out_sample_residuals(\n",
    "    y_true = y_true,\n",
    "    y_pred = y_pred\n",
    ")\n",
    "\n",
    "y_true['_unknown_level'] = np.concatenate([y_true['l2'], y_true['l1']])\n",
    "y_true['l1'] = forecaster.transformer_series_['l1'].transform(y_true['l1'].reshape(-1, 1)).flatten()\n",
    "y_true['l2'] = forecaster.transformer_series_['l2'].transform(y_true['l2'].reshape(-1, 1)).flatten()\n",
    "y_pred['l1'] = forecaster.transformer_series_['l1'].transform(y_pred['l1'].reshape(-1, 1)).flatten()\n",
    "y_pred['l2'] = forecaster.transformer_series_['l2'].transform(y_pred['l2'].reshape(-1, 1)).flatten()\n",
    "y_true['_unknown_level'] = forecaster.transformer_series_['_unknown_level'].transform(y_true['_unknown_level'].reshape(-1, 1)).flatten()\n",
    "y_true['l1'] = forecaster.differentiator_['l1'].transform(y_true['l1'])[forecaster.differentiation_max:]\n",
    "y_true['l2'] = forecaster.differentiator_['l2'].transform(y_true['l2'])[forecaster.differentiation_max:]\n",
    "y_pred['l1'] = forecaster.differentiator_['l1'].transform(y_pred['l1'])[forecaster.differentiation_max:]\n",
    "y_pred['l2'] = forecaster.differentiator_['l2'].transform(y_pred['l2'])[forecaster.differentiation_max:]\n",
    "y_true['_unknown_level'] = forecaster.differentiator_['_unknown_level'].transform(y_true['_unknown_level'])[forecaster.differentiation_max:]\n",
    "residuals = {}\n",
    "residuals['l1'] = y_true['l1'] - y_pred['l1']\n",
    "residuals['l2'] = y_true['l2'] - y_pred['l2']\n",
    "residuals['_unknown_level'] = y_true['_unknown_level'] - np.concatenate([y_pred['l2'], y_pred['l1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: l1\n",
      "key: l2\n"
     ]
    }
   ],
   "source": [
    "for key in residuals.keys():\n",
    "    print(f\"key: {key}\")\n",
    "    np.testing.assert_array_almost_equal(residuals[key], forecaster.out_sample_residuals_[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6845009 , -0.62968343, -0.40829535, -0.31319701, -0.20565481,\n",
       "       -0.1640741 , -0.12075162,  0.73973073,  1.33253838,  2.94977935])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.concatenate([(y_true['l2'] - y_pred['l2']), (y_true['l1'] - y_pred['l1'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l1'] - y_pred['l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l2'] - y_pred['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838,\n",
       "       -0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals['_unknown_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': array([-0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ]),\n",
       " 'l2': array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838]),\n",
       " '_unknown_level': array([-0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ,\n",
       "        -0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.out_sample_residuals_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_14_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
