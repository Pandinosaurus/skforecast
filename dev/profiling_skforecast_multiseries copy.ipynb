{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/joaquin/Documents/GitHub/skforecast'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import skforecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.recursive._forecaster_recursive_multiseries_encoder import ForecasterRecursiveMultiSeriesEncoder\n",
    "from skforecast.model_selection import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection import bayesian_search_forecaster_multiseries\n",
    "from skforecast.model_selection import backtesting_forecaster_multiseries\n",
    "from skforecast.utils import *\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.preprocessing import series_long_to_dict\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "%load_ext pyinstrument\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information system and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.9\n",
      "scikit-learn version: 1.6.1\n",
      "skforecast version: 0.16.0\n",
      "pandas version: 2.2.3\n",
      "numpy version: 2.0.2\n",
      "scipy version: 1.15.2\n",
      "psutil version: 5.9.0\n",
      "\n",
      "Computer network name: joaquin-HP-ProBook-440-G6\n",
      "Machine type: x86_64\n",
      "Processor type: x86_64\n",
      "Platform type: Linux-6.11.0-21-generic-x86_64-with-glibc2.39\n",
      "Operating system: Linux\n",
      "Operating system release: 6.11.0-21-generic\n",
      "Operating system version: #21~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Feb 24 16:52:15 UTC 2\n",
      "Number of physical cores: 4\n",
      "Number of logical cores: 8\n"
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "# ==============================================================================\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"skforecast version: {skforecast.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scipy version: {scipy.__version__}\")\n",
    "print(f\"psutil version: {psutil.__version__}\")\n",
    "print(\"\")\n",
    "\n",
    "# Computer information\n",
    "# ==============================================================================\n",
    "#Computer network name\n",
    "print(f\"Computer network name: {platform.node()}\")\n",
    "#Machine type\n",
    "print(f\"Machine type: {platform.machine()}\")\n",
    "#Processor type\n",
    "print(f\"Processor type: {platform.processor()}\")\n",
    "#Platform type\n",
    "print(f\"Platform type: {platform.platform()}\")\n",
    "#Operating system\n",
    "print(f\"Operating system: {platform.system()}\")\n",
    "#Operating system release\n",
    "print(f\"Operating system release: {platform.release()}\")\n",
    "#Operating system version\n",
    "print(f\"Operating system version: {platform.version()}\")\n",
    "#Physical cores\n",
    "print(f\"Number of physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "#Logical cores\n",
    "print(f\"Number of logical cores: {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForecasterAutoregMultiSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of dates: 2010-01-01 00:00:00 - 2010-07-27 21:00:00\n"
     ]
    }
   ],
   "source": [
    "n_series = 600\n",
    "len_series = (2000, 5000)\n",
    "series_dict = {}\n",
    "rng = np.random.default_rng(321)\n",
    "for i in range(n_series):\n",
    "    n = rng.integers(low=len_series[0], high=len_series[1])\n",
    "    series_dict[f'series_{i}'] = pd.Series(\n",
    "        data = rng.normal(loc=20, scale=5, size=n),\n",
    "        index=pd.date_range(\n",
    "            start='2010-01-01',\n",
    "            periods=n,\n",
    "            freq='h'\n",
    "        ),\n",
    "        name=f'series_{i}'\n",
    "    )\n",
    "\n",
    "exog_dict = {}\n",
    "rng = np.random.default_rng(321)\n",
    "for k in series_dict.keys():\n",
    "    exog = pd.DataFrame(\n",
    "            index=series_dict[k].index\n",
    "            )\n",
    "    exog['day_of_week'] = exog.index.dayofweek\n",
    "    exog['week_of_year'] = exog.index.isocalendar().week.astype(int)\n",
    "    exog['month'] = exog.index.month\n",
    "    exog_dict[k] = exog\n",
    "\n",
    "\n",
    "print(f\"Range of dates: \"\n",
    "    f\"{np.min([series_dict[k].index.min() for k in series_dict.keys()])} - \"\n",
    "    f\"{np.max([series_dict[k].index.max() for k in series_dict.keys()])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_train = '2010-06-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursiveMultiSeriesEncoder(\n",
    "    regressor=LGBMRegressor(random_state=8520, verbose=-1),\n",
    "    lags=50,\n",
    "    # transformer_series=StandardScaler(),\n",
    "    # transformer_exog=StandardScaler(),\n",
    "    encoding=\"ordinal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 1\n",
    "\n",
    "forecaster.fit(series=series_dict, exog=exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pyinstrument\n",
    "\n",
    "# forecaster.fit(series=series_dict, exog=exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 9.61752 s\n",
      "File: /home/joaquin/Documents/GitHub/skforecast/skforecast/recursive/_forecaster_recursive_multiseries_encoder.py\n",
      "Function: fit at line 1642\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1642                                               def fit(\n",
      "  1643                                                   self,\n",
      "  1644                                                   series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "  1645                                                   exog: pd.Series | pd.DataFrame | dict[str, pd.Series | pd.DataFrame] | None = None,\n",
      "  1646                                                   store_last_window: bool | list[str] = True,\n",
      "  1647                                                   store_in_sample_residuals: bool = False,\n",
      "  1648                                                   random_state: int = 123,\n",
      "  1649                                                   suppress_warnings: bool = False\n",
      "  1650                                               ) -> None:\n",
      "  1651                                                   \"\"\"\n",
      "  1652                                                   Training Forecaster. See Notes section for more details depending on \n",
      "  1653                                                   the type of `series` and `exog`.\n",
      "  1654                                           \n",
      "  1655                                                   Additional arguments to be passed to the `fit` method of the regressor \n",
      "  1656                                                   can be added with the `fit_kwargs` argument when initializing the forecaster.\n",
      "  1657                                                   \n",
      "  1658                                                   Parameters\n",
      "  1659                                                   ----------\n",
      "  1660                                                   series : pandas DataFrame, dict\n",
      "  1661                                                       Training time series.\n",
      "  1662                                                   exog : pandas Series, pandas DataFrame, dict, default None\n",
      "  1663                                                       Exogenous variable/s included as predictor/s.\n",
      "  1664                                                   store_last_window : bool, list, default True\n",
      "  1665                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1666                                           \n",
      "  1667                                                       - If `True`, last window is stored for all series. \n",
      "  1668                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1669                                                       - If `False`, last window is not stored.\n",
      "  1670                                                   store_in_sample_residuals : bool, default False\n",
      "  1671                                                       If `True`, in-sample residuals will be stored in the forecaster object\n",
      "  1672                                                       after fitting (`in_sample_residuals_` and `in_sample_residuals_by_bin_`\n",
      "  1673                                                       attributes).\n",
      "  1674                                                       If `False`, only the intervals of the bins are stored.\n",
      "  1675                                                   random_state : int, default 123\n",
      "  1676                                                       Set a seed for the random generator so that the stored sample \n",
      "  1677                                                       residuals are always deterministic.\n",
      "  1678                                                   suppress_warnings : bool, default False\n",
      "  1679                                                       If `True`, skforecast warnings will be suppressed during the training \n",
      "  1680                                                       process. See skforecast.exceptions.warn_skforecast_categories for more\n",
      "  1681                                                       information.\n",
      "  1682                                           \n",
      "  1683                                                   Returns\n",
      "  1684                                                   -------\n",
      "  1685                                                   None\n",
      "  1686                                           \n",
      "  1687                                                   Notes\n",
      "  1688                                                   -----\n",
      "  1689                                                   - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n",
      "  1690                                                   DataFrame, each exog is duplicated for each series. Exog must have the\n",
      "  1691                                                   same index as `series` (type, length and frequency).\n",
      "  1692                                                   - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n",
      "  1693                                                   or DataFrames. Each key in `exog` must be a column in `series` and the \n",
      "  1694                                                   values are the exog for each series. Exog must have the same index as \n",
      "  1695                                                   `series` (type, length and frequency).\n",
      "  1696                                                   - If `series` is a dict of pandas Series, `exog`must be a dict of pandas\n",
      "  1697                                                   Series or DataFrames. The keys in `series` and `exog` must be the same.\n",
      "  1698                                                   All series and exog must have a pandas DatetimeIndex with the same \n",
      "  1699                                                   frequency.\n",
      "  1700                                                   \n",
      "  1701                                                   \"\"\"\n",
      "  1702                                           \n",
      "  1703         1       4523.0   4523.0      0.0          set_skforecast_warnings(suppress_warnings, action='ignore')\n",
      "  1704                                           \n",
      "  1705                                                   # TODO: create a method reset_forecaster() to reset all attributes\n",
      "  1706                                                   # Reset values in case the forecaster has already been fitted.\n",
      "  1707         1       1183.0   1183.0      0.0          self.last_window_                       = None\n",
      "  1708         1        500.0    500.0      0.0          self.index_type_                        = None\n",
      "  1709         1        478.0    478.0      0.0          self.index_freq_                        = None\n",
      "  1710         1        483.0    483.0      0.0          self.training_range_                    = None\n",
      "  1711         1       1674.0   1674.0      0.0          self.series_names_in_                   = None\n",
      "  1712         1        293.0    293.0      0.0          self.exog_in_                           = False\n",
      "  1713         1        315.0    315.0      0.0          self.exog_names_in_                     = None\n",
      "  1714         1        258.0    258.0      0.0          self.exog_type_in_                      = None\n",
      "  1715         1        312.0    312.0      0.0          self.exog_dtypes_in_                    = None\n",
      "  1716         1        873.0    873.0      0.0          self.X_train_series_names_in_           = None\n",
      "  1717         1        550.0    550.0      0.0          self.X_train_window_features_names_out_ = None\n",
      "  1718         1        639.0    639.0      0.0          self.X_train_exog_names_out_            = None\n",
      "  1719         1        342.0    342.0      0.0          self.X_train_features_names_out_        = None\n",
      "  1720         1        167.0    167.0      0.0          self.in_sample_residuals_               = None\n",
      "  1721         1        254.0    254.0      0.0          self.in_sample_residuals_by_bin_        = None\n",
      "  1722         1        832.0    832.0      0.0          self.binner                             = {}\n",
      "  1723         1        750.0    750.0      0.0          self.binner_intervals_                  = {}\n",
      "  1724         1        180.0    180.0      0.0          self.is_fitted                          = False\n",
      "  1725         1        316.0    316.0      0.0          self.fit_date                           = None\n",
      "  1726                                           \n",
      "  1727         1       8391.0   8391.0      0.0          (\n",
      "  1728         1       2916.0   2916.0      0.0              X_train,\n",
      "  1729         1       8240.0   8240.0      0.0              y_train,\n",
      "  1730         1       1675.0   1675.0      0.0              series_indexes,\n",
      "  1731         1        704.0    704.0      0.0              series_names_in_,\n",
      "  1732         1       1582.0   1582.0      0.0              X_train_series_names_in_,\n",
      "  1733         1        284.0    284.0      0.0              exog_names_in_,\n",
      "  1734         1        843.0    843.0      0.0              X_train_window_features_names_out_,\n",
      "  1735         1       1425.0   1425.0      0.0              X_train_exog_names_out_,\n",
      "  1736         1       2738.0   2738.0      0.0              exog_dtypes_in_,\n",
      "  1737         1        668.0    668.0      0.0              last_window_\n",
      "  1738         2 1652045083.0    8e+08     17.2          ) = self._create_train_X_y(\n",
      "  1739         1        184.0    184.0      0.0                  series=series, exog=exog, store_last_window=store_last_window\n",
      "  1740                                                       )\n",
      "  1741                                           \n",
      "  1742         2      70776.0  35388.0      0.0          sample_weight = self.create_sample_weights(\n",
      "  1743         1       2545.0   2545.0      0.0                              series_names_in_ = series_names_in_,\n",
      "  1744         1       1072.0   1072.0      0.0                              X_train          = X_train\n",
      "  1745                                                                   )\n",
      "  1746                                           \n",
      "  1747         1       1543.0   1543.0      0.0          X_train_regressor = (\n",
      "  1748         1       2863.0   2863.0      0.0              X_train\n",
      "  1749         1       1957.0   1957.0      0.0              if self.encoding is not None\n",
      "  1750                                                       else X_train.drop(columns=\"_level_skforecast\")\n",
      "  1751                                                   )\n",
      "  1752         1      31458.0  31458.0      0.0          if sample_weight is not None:\n",
      "  1753                                                       self.regressor.fit(\n",
      "  1754                                                           X             = X_train_regressor,\n",
      "  1755                                                           y             = y_train,\n",
      "  1756                                                           sample_weight = sample_weight,\n",
      "  1757                                                           **self.fit_kwargs\n",
      "  1758                                                       )\n",
      "  1759                                                   else:\n",
      "  1760         1 6222983985.0    6e+09     64.7              self.regressor.fit(X=X_train_regressor, y=y_train, **self.fit_kwargs)\n",
      "  1761                                           \n",
      "  1762         1       1909.0   1909.0      0.0          self.series_names_in_ = series_names_in_\n",
      "  1763         1        592.0    592.0      0.0          self.X_train_series_names_in_ = X_train_series_names_in_\n",
      "  1764         1        413.0    413.0      0.0          self.X_train_window_features_names_out_ = X_train_window_features_names_out_\n",
      "  1765         1       9988.0   9988.0      0.0          self.X_train_features_names_out_ = X_train_regressor.columns.to_list()\n",
      "  1766                                           \n",
      "  1767         1        330.0    330.0      0.0          self.is_fitted = True\n",
      "  1768         1      52336.0  52336.0      0.0          self.fit_date = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
      "  1769       251   80221930.0 319609.3      0.8          self.training_range_ = {k: v[[0, -1]] for k, v in series_indexes.items()}\n",
      "  1770         1       4117.0   4117.0      0.0          self.index_type_ = type(series_indexes[series_names_in_[0]])\n",
      "  1771         1       1175.0   1175.0      0.0          if isinstance(series_indexes[series_names_in_[0]], pd.DatetimeIndex):\n",
      "  1772         1      22909.0  22909.0      0.0              self.index_freq_ = series_indexes[series_names_in_[0]].freqstr\n",
      "  1773                                                   else:\n",
      "  1774                                                       self.index_freq_ = series_indexes[series_names_in_[0]].step\n",
      "  1775                                           \n",
      "  1776         1        389.0    389.0      0.0          if exog is not None:\n",
      "  1777         1        318.0    318.0      0.0              self.exog_in_ = True\n",
      "  1778         1        283.0    283.0      0.0              self.exog_names_in_ = exog_names_in_\n",
      "  1779         1        411.0    411.0      0.0              self.exog_type_in_ = type(exog)\n",
      "  1780         1        539.0    539.0      0.0              self.exog_dtypes_in_ = exog_dtypes_in_\n",
      "  1781         1        279.0    279.0      0.0              self.X_train_exog_names_out_ = X_train_exog_names_out_\n",
      "  1782                                           \n",
      "  1783         1        317.0    317.0      0.0          self.in_sample_residuals_ = {}\n",
      "  1784         1        635.0    635.0      0.0          self.in_sample_residuals_by_bin_ = {}\n",
      "  1785         1        508.0    508.0      0.0          if self._probabilistic_mode is not False:\n",
      "  1786         1  740654245.0    7e+08      7.7              y_pred = self.regressor.predict(X_train_regressor)\n",
      "  1787         1       4194.0   4194.0      0.0              if self.encoding is not None:\n",
      "  1788       251     303333.0   1208.5      0.0                  for level in X_train_series_names_in_:\n",
      "  1789       250     202166.0    808.7      0.0                      if self.encoding == 'onehot':\n",
      "  1790                                                                   mask = X_train[level].to_numpy() == 1.\n",
      "  1791                                                               else:\n",
      "  1792       250     173287.0    693.1      0.0                          encoded_value = self.encoding_mapping_[level]\n",
      "  1793       250  254501820.0    1e+06      2.6                          mask = X_train['_level_skforecast'].to_numpy() == encoded_value\n",
      "  1794                                           \n",
      "  1795       500  239311966.0 478623.9      2.5                      self._binning_in_sample_residuals(\n",
      "  1796       250      88205.0    352.8      0.0                          level                     = level,\n",
      "  1797       250  350993944.0    1e+06      3.6                          y_true                    = y_train[mask],\n",
      "  1798       250   60571439.0 242285.8      0.6                          y_pred                    = y_pred[mask],\n",
      "  1799       250     104608.0    418.4      0.0                          store_in_sample_residuals = store_in_sample_residuals,\n",
      "  1800       250      58475.0    233.9      0.0                          random_state              = random_state\n",
      "  1801                                                               )\n",
      "  1802                                                       \n",
      "  1803                                                       # NOTE: the _unknown_level is a random sample of 10_000 residuals of all levels.\n",
      "  1804         2   14863150.0    7e+06      0.2              self._binning_in_sample_residuals(\n",
      "  1805         1        241.0    241.0      0.0                  level                     = '_unknown_level',\n",
      "  1806         1        160.0    160.0      0.0                  y_true                    = y_train,\n",
      "  1807         1        139.0    139.0      0.0                  y_pred                    = y_pred,\n",
      "  1808         1        159.0    159.0      0.0                  store_in_sample_residuals = store_in_sample_residuals,\n",
      "  1809         1        133.0    133.0      0.0                  random_state              = random_state\n",
      "  1810                                                       )\n",
      "  1811                                                   \n",
      "  1812         1        418.0    418.0      0.0          if not store_in_sample_residuals:\n",
      "  1813                                                       # NOTE: create empty dictionaries to avoid errors when calling predict()\n",
      "  1814         1       1308.0   1308.0      0.0              if self.encoding is not None:\n",
      "  1815       251      63632.0    253.5      0.0                  for level in X_train_series_names_in_:\n",
      "  1816       250      57721.0    230.9      0.0                      self.in_sample_residuals_[level] = None\n",
      "  1817       250      56244.0    225.0      0.0                      self.in_sample_residuals_by_bin_[level] = None\n",
      "  1818         1        651.0    651.0      0.0              self.in_sample_residuals_['_unknown_level'] = None\n",
      "  1819         1        323.0    323.0      0.0              self.in_sample_residuals_by_bin_['_unknown_level'] = None\n",
      "  1820                                           \n",
      "  1821         1        268.0    268.0      0.0          if store_last_window:\n",
      "  1822         1        659.0    659.0      0.0              self.last_window_ = last_window_\n",
      "  1823                                                   \n",
      "  1824         1       5738.0   5738.0      0.0          set_skforecast_warnings(suppress_warnings, action='default')"
     ]
    }
   ],
   "source": [
    "# Profiling fit()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, series, exog):\n",
    "    forecaster.fit(series=series, exog=exog)\n",
    "\n",
    "%lprun -f forecaster.fit funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 1.49029 s\n",
      "File: /home/joaquin/Documents/GitHub/skforecast/skforecast/recursive/_forecaster_recursive_multiseries_encoder.py\n",
      "Function: _create_train_X_y at line 958\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   958                                               def _create_train_X_y(\n",
      "   959                                                   self,\n",
      "   960                                                   series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "   961                                                   exog: pd.Series | pd.DataFrame | dict[str, pd.Series | pd.DataFrame] | None = None,\n",
      "   962                                                   store_last_window: bool | list[str] = True,\n",
      "   963                                               ) -> tuple[\n",
      "   964                                                   pd.DataFrame,\n",
      "   965                                                   pd.Series,\n",
      "   966                                                   dict[str, pd.Index],\n",
      "   967                                                   list[str],\n",
      "   968                                                   list[str],\n",
      "   969                                                   list[str],\n",
      "   970                                                   list[str],\n",
      "   971                                                   list[str],\n",
      "   972                                                   dict[str, type],\n",
      "   973                                                   dict[str, pd.Series],\n",
      "   974                                               ]:\n",
      "   975                                                   \"\"\"\n",
      "   976                                                   Create training matrices from multiple time series and exogenous\n",
      "   977                                                   variables. See Notes section for more details depending on the type of\n",
      "   978                                                   `series` and `exog`.\n",
      "   979                                                   \n",
      "   980                                                   Parameters\n",
      "   981                                                   ----------\n",
      "   982                                                   series : pandas DataFrame, dict\n",
      "   983                                                       Training time series.\n",
      "   984                                                   exog : pandas Series, pandas DataFrame, dict, default None\n",
      "   985                                                       Exogenous variable/s included as predictor/s.\n",
      "   986                                                   store_last_window : bool, list, default True\n",
      "   987                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "   988                                           \n",
      "   989                                                       - If `True`, last window is stored for all series. \n",
      "   990                                                       - If `list`, last window is stored for the series present in the list.\n",
      "   991                                                       - If `False`, last window is not stored.\n",
      "   992                                           \n",
      "   993                                                   Returns\n",
      "   994                                                   -------\n",
      "   995                                                   X_train : pandas DataFrame\n",
      "   996                                                       Training values (predictors).\n",
      "   997                                                   y_train : pandas Series\n",
      "   998                                                       Values of the time series related to each row of `X_train`.\n",
      "   999                                                   series_indexes : dict\n",
      "  1000                                                       Dictionary with the index of each series.\n",
      "  1001                                                   series_names_in_ : list\n",
      "  1002                                                       Names of the series (levels) provided by the user during training.\n",
      "  1003                                                   X_train_series_names_in_ : list\n",
      "  1004                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1005                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1006                                                       some series are dropped during the training process because of NaNs or\n",
      "  1007                                                       because they are not present in the training period.\n",
      "  1008                                                   exog_names_in_ : list\n",
      "  1009                                                       Names of the exogenous variables used during training.\n",
      "  1010                                                   X_train_window_features_names_out_ : list\n",
      "  1011                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1012                                                       internally for training.\n",
      "  1013                                                   X_train_exog_names_out_ : list\n",
      "  1014                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1015                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1016                                                       some exogenous variables are transformed during the training process.\n",
      "  1017                                                   exog_dtypes_in_ : dict\n",
      "  1018                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1019                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1020                                                   last_window_ : dict\n",
      "  1021                                                       Last window of training data for each series. It stores the values \n",
      "  1022                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1023                                           \n",
      "  1024                                                   Notes\n",
      "  1025                                                   -----\n",
      "  1026                                                   - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n",
      "  1027                                                   DataFrame, each exog is duplicated for each series. Exog must have the\n",
      "  1028                                                   same index as `series` (type, length and frequency).\n",
      "  1029                                                   - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n",
      "  1030                                                   or DataFrames. Each key in `exog` must be a column in `series` and the \n",
      "  1031                                                   values are the exog for each series. Exog must have the same index as \n",
      "  1032                                                   `series` (type, length and frequency).\n",
      "  1033                                                   - If `series` is a dict of pandas Series, `exog` must be a dict of pandas\n",
      "  1034                                                   Series or DataFrames. The keys in `series` and `exog` must be the same.\n",
      "  1035                                                   All series and exog must have a pandas DatetimeIndex with the same \n",
      "  1036                                                   frequency.\n",
      "  1037                                                   \n",
      "  1038                                                   \"\"\"\n",
      "  1039                                           \n",
      "  1040         1   57600566.0    6e+07      3.9          series_dict, series_indexes = check_preprocess_series(series=series)\n",
      "  1041         1        746.0    746.0      0.0          input_series_is_dict = isinstance(series, dict)\n",
      "  1042         1       3490.0   3490.0      0.0          series_names_in_ = list(series_dict.keys())\n",
      "  1043                                           \n",
      "  1044         1      21401.0  21401.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1045                                                       raise ValueError(\n",
      "  1046                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1047                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1048                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1049                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1050                                                       )\n",
      "  1051                                           \n",
      "  1052       251      72639.0    289.4      0.0          exog_dict = {serie: None for serie in series_names_in_}\n",
      "  1053         1        192.0    192.0      0.0          exog_names_in_ = None\n",
      "  1054         1        151.0    151.0      0.0          X_train_exog_names_out_ = None\n",
      "  1055         1        279.0    279.0      0.0          if exog is not None:\n",
      "  1056         2  113046907.0    6e+07      7.6              exog_dict, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1057         1        179.0    179.0      0.0                                              input_series_is_dict = input_series_is_dict,\n",
      "  1058         1        168.0    168.0      0.0                                              series_indexes       = series_indexes,\n",
      "  1059         1        144.0    144.0      0.0                                              series_names_in_     = series_names_in_,\n",
      "  1060         1        136.0    136.0      0.0                                              exog                 = exog,\n",
      "  1061         1        130.0    130.0      0.0                                              exog_dict            = exog_dict\n",
      "  1062                                                                                   )\n",
      "  1063                                           \n",
      "  1064         1        791.0    791.0      0.0              if self.is_fitted:\n",
      "  1065         1        566.0    566.0      0.0                  if self.exog_names_in_ is None:\n",
      "  1066                                                               raise ValueError(\n",
      "  1067                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1068                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1069                                                               )\n",
      "  1070                                                           else:\n",
      "  1071         1       1561.0   1561.0      0.0                      if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1072                                                                   raise ValueError(\n",
      "  1073                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1074                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1075                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1076                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1077                                                                   )\n",
      "  1078                                           \n",
      "  1079         1        287.0    287.0      0.0          if not self.is_fitted:\n",
      "  1080                                                       self.transformer_series_ = initialize_transformer_series(\n",
      "  1081                                                                                      forecaster_name    = type(self).__name__,\n",
      "  1082                                                                                      series_names_in_   = series_names_in_,\n",
      "  1083                                                                                      encoding           = self.encoding,\n",
      "  1084                                                                                      transformer_series = self.transformer_series\n",
      "  1085                                                                                  )\n",
      "  1086                                                       \n",
      "  1087                                                       self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1088                                                                                  series_names_in_ = series_names_in_,\n",
      "  1089                                                                                  differentiator   = self.differentiator\n",
      "  1090                                                                              )\n",
      "  1091                                           \n",
      "  1092         2   17345012.0    9e+06      1.2          series_dict, exog_dict = align_series_and_exog_multiseries(\n",
      "  1093         1        267.0    267.0      0.0                                       series_dict          = series_dict,\n",
      "  1094         1        172.0    172.0      0.0                                       input_series_is_dict = input_series_is_dict,\n",
      "  1095         1        138.0    138.0      0.0                                       exog_dict            = exog_dict\n",
      "  1096                                                                            )\n",
      "  1097                                                   \n",
      "  1098         1       1506.0   1506.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1099                                                       self.transformer_series_['_unknown_level'].fit(\n",
      "  1100                                                           np.concatenate(list(series_dict.values())).reshape(-1, 1)\n",
      "  1101                                                       )\n",
      "  1102                                           \n",
      "  1103         1        931.0    931.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1104         2       1103.0    551.5      0.0          input_matrices = [\n",
      "  1105       250     155035.0    620.1      0.0              [series_dict[k], exog_dict[k], ignore_exog]\n",
      "  1106       252      98249.0    389.9      0.0               for k in series_dict.keys()\n",
      "  1107                                                   ]\n",
      "  1108                                           \n",
      "  1109         1        381.0    381.0      0.0          X_train_autoreg_buffer = []\n",
      "  1110         1        636.0    636.0      0.0          X_train_exog_buffer = []\n",
      "  1111         1        415.0    415.0      0.0          y_train_buffer = []\n",
      "  1112       251     253977.0   1011.9      0.0          for matrices in input_matrices:\n",
      "  1113                                           \n",
      "  1114       250     292822.0   1171.3      0.0              (\n",
      "  1115       250      87572.0    350.3      0.0                  X_train_autoreg,\n",
      "  1116       250      46388.0    185.6      0.0                  X_train_window_features_names_out_,\n",
      "  1117       250      53231.0    212.9      0.0                  X_train_exog,\n",
      "  1118       250     725218.0   2900.9      0.0                  y_train\n",
      "  1119       500  481736996.0 963474.0     32.3              ) = self._create_train_X_y_single_series(\n",
      "  1120       250     129928.0    519.7      0.0                  y           = matrices[0],\n",
      "  1121       250     338516.0   1354.1      0.0                  exog        = matrices[1],\n",
      "  1122       250     329748.0   1319.0      0.0                  ignore_exog = matrices[2],\n",
      "  1123                                                       )\n",
      "  1124                                           \n",
      "  1125       250     838575.0   3354.3      0.1              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1126       250     582413.0   2329.7      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1127       250     402732.0   1610.9      0.0              y_train_buffer.append(y_train)\n",
      "  1128                                           \n",
      "  1129         1  279023015.0    3e+08     18.7          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1130         1   18889888.0    2e+07      1.3          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1131                                           \n",
      "  1132         1       4500.0   4500.0      0.0          if self.is_fitted:\n",
      "  1133         1       3320.0   3320.0      0.0              if self.encoding == 'onehot':\n",
      "  1134                                                           encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1135                                                       else:\n",
      "  1136         1   64157073.0    6e+07      4.3                  encoded_values = self.encoder.transform(X_train['_level_skforecast'])\n",
      "  1137                                                   else:\n",
      "  1138                                                       if self.encoding == 'onehot':\n",
      "  1139                                                           encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1140                                                           for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1141                                                               self.encoding_mapping_[code] = i\n",
      "  1142                                                       else:\n",
      "  1143                                                           self.encoder.fit(series_names_in_)\n",
      "  1144                                                           encoded_values = self.encoder.transform(X_train['_level_skforecast'])\n",
      "  1145                                                           self.encoding_mapping_ = self.encoder.category_map_\n",
      "  1146                                                   \n",
      "  1147         1       4820.0   4820.0      0.0          if self.encoding == 'onehot': \n",
      "  1148                                                       X_train = pd.concat([\n",
      "  1149                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1150                                                                     encoded_values\n",
      "  1151                                                                 ], axis=1)\n",
      "  1152                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1153                                                   else:\n",
      "  1154         1    5129736.0    5e+06      0.3              X_train['_level_skforecast'] = encoded_values\n",
      "  1155                                           \n",
      "  1156         1       6170.0   6170.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1157                                                       X_train['_level_skforecast'] = (\n",
      "  1158                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1159                                                       )\n",
      "  1160                                           \n",
      "  1161         1      11849.0  11849.0      0.0          del encoded_values\n",
      "  1162                                           \n",
      "  1163         1       3218.0   3218.0      0.0          exog_dtypes_in_ = None\n",
      "  1164         1       3824.0   3824.0      0.0          if exog is not None:\n",
      "  1165                                           \n",
      "  1166         1   37783196.0    4e+07      2.5              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1167         1      59416.0  59416.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1168                                                           X_train_exog = (\n",
      "  1169                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1170                                                           )\n",
      "  1171                                           \n",
      "  1172         1      16789.0  16789.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1173         1     586310.0 586310.0      0.0              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1174                                           \n",
      "  1175         1      13215.0  13215.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1176         2      17510.0   8755.0      0.0              X_train_exog = transform_dataframe(\n",
      "  1177         1       4560.0   4560.0      0.0                                 df                = X_train_exog,\n",
      "  1178         1       7205.0   7205.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1179         1       5388.0   5388.0      0.0                                 fit               = fit_transformer,\n",
      "  1180         1       5222.0   5222.0      0.0                                 inverse_transform = False\n",
      "  1181                                                                      )\n",
      "  1182                                           \n",
      "  1183         1     502976.0 502976.0      0.0              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1184         1    7493405.0    7e+06      0.5              if not (X_train_exog.index == X_train.index).all():\n",
      "  1185                                                           raise ValueError(\n",
      "  1186                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1187                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1188                                                           )\n",
      "  1189                                           \n",
      "  1190         1      19753.0  19753.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1191         1  234356238.0    2e+08     15.7              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1192                                           \n",
      "  1193         1    2122860.0    2e+06      0.1          if y_train.isnull().any():\n",
      "  1194                                                       mask = y_train.notna().to_numpy()\n",
      "  1195                                                       y_train = y_train.iloc[mask]\n",
      "  1196                                                       X_train = X_train.iloc[mask,]\n",
      "  1197                                                       warnings.warn(\n",
      "  1198                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1199                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1200                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1201                                                           \"series with interspersed NaNs.\",\n",
      "  1202                                                           MissingValuesWarning\n",
      "  1203                                                       )\n",
      "  1204                                           \n",
      "  1205         1       7381.0   7381.0      0.0          if self.dropna_from_series:\n",
      "  1206                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1207                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1208                                                           X_train = X_train.iloc[mask, ]\n",
      "  1209                                                           y_train = y_train.iloc[mask]\n",
      "  1210                                                           warnings.warn(\n",
      "  1211                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1212                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1213                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1214                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1215                                                               MissingValuesWarning\n",
      "  1216                                                           )\n",
      "  1217                                                   else:\n",
      "  1218         1  109994581.0    1e+08      7.4              if np.any(X_train.isnull().to_numpy()):\n",
      "  1219                                                           warnings.warn(\n",
      "  1220                                                               \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1221                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1222                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1223                                                               MissingValuesWarning\n",
      "  1224                                                           )\n",
      "  1225                                           \n",
      "  1226         1      40171.0  40171.0      0.0          if X_train.empty:\n",
      "  1227                                                       raise ValueError(\n",
      "  1228                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1229                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1230                                                       )\n",
      "  1231                                                   \n",
      "  1232         1       6564.0   6564.0      0.0          if self.encoding == 'onehot':\n",
      "  1233                                                       X_train_series_names_in_ = [\n",
      "  1234                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1235                                                       ]\n",
      "  1236                                                   else:\n",
      "  1237         1    6134112.0    6e+06      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1238         2      13990.0   6995.0      0.0              X_train_series_names_in_ = [\n",
      "  1239       502    5443173.0  10843.0      0.4                  k for k, v in self.encoding_mapping_.items()\n",
      "  1240       250    2728155.0  10912.6      0.2                  if v in unique_levels\n",
      "  1241                                                       ]\n",
      "  1242                                           \n",
      "  1243                                                   # The last time window of training data is stored so that lags needed as\n",
      "  1244                                                   # predictors in the first iteration of `predict()` can be calculated.\n",
      "  1245         1       5518.0   5518.0      0.0          last_window_ = None\n",
      "  1246         1       4944.0   4944.0      0.0          if store_last_window:\n",
      "  1247                                           \n",
      "  1248         1       6927.0   6927.0      0.0              series_to_store = (\n",
      "  1249         1       5527.0   5527.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1250                                                       )\n",
      "  1251                                           \n",
      "  1252         1      50433.0  50433.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1253         1       7727.0   7727.0      0.0              if series_not_in_series_dict:\n",
      "  1254                                                           warnings.warn(\n",
      "  1255                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1256                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1257                                                               IgnoredArgumentWarning\n",
      "  1258                                                           )\n",
      "  1259                                                           series_to_store = [\n",
      "  1260                                                               s for s in series_to_store \n",
      "  1261                                                               if s not in series_not_in_series_dict\n",
      "  1262                                                           ]\n",
      "  1263                                           \n",
      "  1264         1       5488.0   5488.0      0.0              if series_to_store:\n",
      "  1265         2      12177.0   6088.5      0.0                  last_window_ = {\n",
      "  1266       250   37728729.0 150914.9      2.5                      k: v.iloc[-self.window_size:].copy()\n",
      "  1267       252    1555139.0   6171.2      0.1                      for k, v in series_dict.items()\n",
      "  1268       250    2076128.0   8304.5      0.1                      if k in series_to_store\n",
      "  1269                                                           }\n",
      "  1270                                           \n",
      "  1271         1       3001.0   3001.0      0.0          return (\n",
      "  1272         1       5559.0   5559.0      0.0              X_train,\n",
      "  1273         1       5903.0   5903.0      0.0              y_train,\n",
      "  1274         1       5309.0   5309.0      0.0              series_indexes,\n",
      "  1275         1       5269.0   5269.0      0.0              series_names_in_,\n",
      "  1276         1       5257.0   5257.0      0.0              X_train_series_names_in_,\n",
      "  1277         1       5277.0   5277.0      0.0              exog_names_in_,\n",
      "  1278         1       5368.0   5368.0      0.0              X_train_window_features_names_out_,\n",
      "  1279         1       5523.0   5523.0      0.0              X_train_exog_names_out_,\n",
      "  1280         1       5343.0   5343.0      0.0              exog_dtypes_in_,\n",
      "  1281         1       5285.0   5285.0      0.0              last_window_\n",
      "  1282                                                   )"
     ]
    }
   ],
   "source": [
    "# Profiling _create_train_X_y()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, series, exog):\n",
    "    forecaster._create_train_X_y(series=series, exog=exog)\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3549\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[11]\u001b[39m\u001b[92m, line 15\u001b[39m\n    get_ipython().run_line_magic('lprun', \"-f forecaster._create_train_X_y_single_series funt_to_profile(forecaster, series_dict['series_0'], exog_dict['series_0'])\")\n",
      "  File \u001b[92mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2481\u001b[39m in \u001b[95mrun_line_magic\u001b[39m\n    result = fn(*args, **kwargs)\n",
      "  File \u001b[92mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\line_profiler\\ipython_extension.py:130\u001b[39m in \u001b[95mlprun\u001b[39m\n    profile.runctx(arg_str, global_ns, local_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\line_profiler\\line_profiler.py:185\u001b[39m\u001b[36m in \u001b[39m\u001b[35mrunctx\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(cmd, globals, locals)\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfunt_to_profile(forecaster, series_dict[\\'series_0\\'], exog_dict[\\'series_0\\'])\u001b[39m\n                                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# Profiling _create_train_X_y_single_series()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, series, exog):\n",
    "    (\n",
    "    X_train_autoreg,\n",
    "    X_train_window_features_names_out_,\n",
    "    X_train_exog,\n",
    "    y_train\n",
    ") = forecaster._create_train_X_y_single_series(\n",
    "        y = series,\n",
    "        exog = exog,\n",
    "        ignore_exog = False,\n",
    "    )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y_single_series funt_to_profile(forecaster, series_dict['series_0'], exog_dict['series_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 36.6131 s\n",
      "File: /home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py\n",
      "Function: predict at line 1537\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1537                                               def predict(\n",
      "  1538                                                   self,\n",
      "  1539                                                   steps: int,\n",
      "  1540                                                   levels: Optional[Union[str, list]]=None,\n",
      "  1541                                                   last_window: Optional[pd.DataFrame]=None,\n",
      "  1542                                                   exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None,\n",
      "  1543                                                   suppress_warnings: bool=False\n",
      "  1544                                               ) -> pd.DataFrame:\n",
      "  1545                                                   \"\"\"\n",
      "  1546                                                   Predict n steps ahead. It is an recursive process in which, each prediction,\n",
      "  1547                                                   is used as a predictor for the next step. Only levels whose last window\n",
      "  1548                                                   ends at the same datetime index can be predicted together.\n",
      "  1549                                           \n",
      "  1550                                                   Parameters\n",
      "  1551                                                   ----------\n",
      "  1552                                                   steps : int\n",
      "  1553                                                       Number of future steps predicted.\n",
      "  1554                                                   levels : str, list, default `None`\n",
      "  1555                                                       Time series to be predicted. If `None` all levels whose last window\n",
      "  1556                                                       ends at the same datetime index will be predicted together.\n",
      "  1557                                                   last_window : pandas DataFrame, default `None`\n",
      "  1558                                                       Series values used to create the predictors (lags) needed in the \n",
      "  1559                                                       first iteration of the prediction (t + 1).\n",
      "  1560                                                       If `last_window = None`, the values stored in `self.last_window` are\n",
      "  1561                                                       used to calculate the initial predictors, and the predictions start\n",
      "  1562                                                       right after training data.\n",
      "  1563                                                   exog : pandas Series, pandas DataFrame, dict, default `None`\n",
      "  1564                                                       Exogenous variable/s included as predictor/s.\n",
      "  1565                                                   suppress_warnings : bool, default `False`\n",
      "  1566                                                       If `True`, skforecast warnings will be suppressed during the prediction \n",
      "  1567                                                       process. See skforecast.exceptions.warn_skforecast_categories for more\n",
      "  1568                                                       information.\n",
      "  1569                                           \n",
      "  1570                                                   Returns\n",
      "  1571                                                   -------\n",
      "  1572                                                   predictions : pandas DataFrame\n",
      "  1573                                                       Predicted values, one column for each level.\n",
      "  1574                                           \n",
      "  1575                                                   \"\"\"\n",
      "  1576                                           \n",
      "  1577         1      60301.0  60301.0      0.0          set_skforecast_warnings(suppress_warnings, action='ignore')\n",
      "  1578                                           \n",
      "  1579         1       1960.0   1960.0      0.0          (\n",
      "  1580         1        710.0    710.0      0.0              last_window_values_dict,\n",
      "  1581         1        360.0    360.0      0.0              exog_values_dict,\n",
      "  1582         1        300.0    300.0      0.0              levels,\n",
      "  1583         1        400.0    400.0      0.0              prediction_index,\n",
      "  1584         1        520.0    520.0      0.0              _\n",
      "  1585         2        2e+10    1e+10     52.8          ) = self._create_predict_inputs(\n",
      "  1586         1        220.0    220.0      0.0              steps       = steps,\n",
      "  1587         1        200.0    200.0      0.0              levels      = levels,\n",
      "  1588         1        210.0    210.0      0.0              last_window = last_window,\n",
      "  1589         1        190.0    190.0      0.0              exog        = exog\n",
      "  1590                                                   )\n",
      "  1591                                           \n",
      "  1592         1        440.0    440.0      0.0          predictions = []\n",
      "  1593      1579     777563.0    492.4      0.0          for level in levels:\n",
      "  1594                                           \n",
      "  1595      3156        2e+10    5e+06     46.0              preds_level = self._recursive_predict(\n",
      "  1596      1578     389436.0    246.8      0.0                                steps       = steps,\n",
      "  1597      1578     382309.0    242.3      0.0                                level       = level,\n",
      "  1598      1578    1154419.0    731.6      0.0                                last_window = last_window_values_dict[level],\n",
      "  1599      1578     973106.0    616.7      0.0                                exog        = exog_values_dict[level]\n",
      "  1600                                                                     )\n",
      "  1601                                                   \n",
      "  1602      1578    1244621.0    788.7      0.0              if self.differentiation is not None:\n",
      "  1603                                                           preds_level = self.differentiator_[level].inverse_transform_next_window(preds_level)\n",
      "  1604                                           \n",
      "  1605      3156  194722123.0  61699.0      0.5              preds_level = pd.Series(\n",
      "  1606      1578     440570.0    279.2      0.0                                data  = preds_level,\n",
      "  1607      1578     483597.0    306.5      0.0                                index = prediction_index,\n",
      "  1608      1578     387574.0    245.6      0.0                                name  = level\n",
      "  1609                                                                     )\n",
      "  1610                                           \n",
      "  1611      3156    4344345.0   1376.5      0.0              preds_level = transform_series(\n",
      "  1612      1578     472086.0    299.2      0.0                                series            = preds_level,\n",
      "  1613      1578    1646270.0   1043.3      0.0                                transformer       = self.transformer_series_[level],\n",
      "  1614      1578     440865.0    279.4      0.0                                fit               = False,\n",
      "  1615      1578     386664.0    245.0      0.0                                inverse_transform = True\n",
      "  1616                                                                     )\n",
      "  1617                                           \n",
      "  1618      1578    1421995.0    901.1      0.0              predictions.append(preds_level)\n",
      "  1619                                           \n",
      "  1620         1  228002906.0    2e+08      0.6          predictions = pd.concat(predictions, axis=1)\n",
      "  1621                                                   \n",
      "  1622         1      68061.0  68061.0      0.0          set_skforecast_warnings(suppress_warnings, action='default')\n",
      "  1623                                           \n",
      "  1624         1        240.0    240.0      0.0          return predictions"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling predict()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(forecaster, steps, exog):\n",
    "    forecaster.predict(steps=steps, exog=exog, suppress_warnings=True)\n",
    "\n",
    "%lprun -f forecaster.predict funt_to_profile(forecaster, 7, exog_dict_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Functions to profile:\n",
    "# ==============================================================================\n",
    "# check_preprocess_exog_multiseries\n",
    "# align_series_and_exog_multiseries\n",
    "# _create_train_X_y_single_series\n",
    "# _create_predict_inputs\n",
    "# _recursive_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Profiling align_series_and_exog_multiseries()\n",
    "# ==============================================================================\n",
    "# def funt_to_profile(series_dict, input_series_is_dict, exog_dict):\n",
    "#     align_series_and_exog_multiseries(\n",
    "#         series_dict=series_dict,\n",
    "#         input_series_is_dict=input_series_is_dict,\n",
    "#         exog_dict = exog_dict,\n",
    "#     )\n",
    "\n",
    "# %lprun -f align_series_and_exog_multiseries funt_to_profile(series_dict_train, True, exog_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Profiling check_preprocess_exog_multiseries()\n",
    "# # ==============================================================================\n",
    "# series_indexes = {k: v.index for k, v  in series_dict_train.items()}\n",
    "# series_col_names = list(series_dict_train.keys())\n",
    "\n",
    "# def funt_to_profile(input_series_is_dict, series_indexes, series_col_names, exog, exog_dict):\n",
    "#     check_preprocess_exog_multiseries(\n",
    "#         input_series_is_dict = input_series_is_dict,\n",
    "#         series_indexes = series_indexes,\n",
    "#         series_col_names = series_col_names,\n",
    "#         exog = exog_dict_train,\n",
    "#         exog_dict = exog_dict_train,\n",
    "#     )\n",
    "\n",
    "# %lprun -f check_preprocess_exog_multiseries funt_to_profile(True, series_indexes, series_col_names, exog, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunt_to_profile\u001b[39m(data):\n\u001b[32m      4\u001b[39m     fast_encoder.fit(data)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m data_np = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.to_numpy()\n\u001b[32m      7\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mlprun\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-f fast_encoder.fit funt_to_profile(data_np)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_p12/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_p12/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_p12/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'y'"
     ]
    }
   ],
   "source": [
    "# Profiling predict()\n",
    "# ==============================================================================\n",
    "def funt_to_profile(data):\n",
    "    fast_encoder.fit(data)\n",
    "\n",
    "data_np = data['y'].to_numpy()\n",
    "%lprun -f fast_encoder.fit funt_to_profile(data_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_16_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
