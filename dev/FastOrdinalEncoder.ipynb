{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import skforecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection import bayesian_search_forecaster_multiseries\n",
    "from skforecast.model_selection import backtesting_forecaster_multiseries\n",
    "from skforecast.utils import *\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.preprocessing import series_long_to_dict\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "%load_ext pyinstrument\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information system and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.10\n",
      "scikit-learn version: 1.6.1\n",
      "skforecast version: 0.16.0\n",
      "pandas version: 2.2.3\n",
      "numpy version: 2.1.3\n",
      "scipy version: 1.15.2\n",
      "psutil version: 7.0.0\n",
      "\n",
      "Computer network name: ITES015-NB0029\n",
      "Machine type: AMD64\n",
      "Processor type: Intel64 Family 6 Model 141 Stepping 1, GenuineIntel\n",
      "Platform type: Windows-10-10.0.19045-SP0\n",
      "Operating system: Windows\n",
      "Operating system release: 10\n",
      "Operating system version: 10.0.19045\n",
      "Number of physical cores: 8\n",
      "Number of logical cores: 16\n"
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "# ==============================================================================\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"skforecast version: {skforecast.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scipy version: {scipy.__version__}\")\n",
    "print(f\"psutil version: {psutil.__version__}\")\n",
    "print(\"\")\n",
    "\n",
    "# Computer information\n",
    "# ==============================================================================\n",
    "#Computer network name\n",
    "print(f\"Computer network name: {platform.node()}\")\n",
    "#Machine type\n",
    "print(f\"Machine type: {platform.machine()}\")\n",
    "#Processor type\n",
    "print(f\"Processor type: {platform.processor()}\")\n",
    "#Platform type\n",
    "print(f\"Platform type: {platform.platform()}\")\n",
    "#Operating system\n",
    "print(f\"Operating system: {platform.system()}\")\n",
    "#Operating system release\n",
    "print(f\"Operating system release: {platform.release()}\")\n",
    "#Operating system version\n",
    "print(f\"Operating system version: {platform.version()}\")\n",
    "#Physical cores\n",
    "print(f\"Number of physical cores: {psutil.cpu_count(logical=False)}\")\n",
    "#Logical cores\n",
    "print(f\"Number of logical cores: {psutil.cpu_count(logical=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn OrdinalEncoder time: 0.1126 seconds\n",
      "FastOrdinalEncoder time: 0.0297 seconds\n",
      "All encoders produced the same results.\n",
      "Inverse transform works correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "class FastOrdinalEncoder:\n",
    "    \"\"\"\n",
    "    Encode categorical values as an integer array, with integer values\n",
    "    from 0 to n_categories - 1.\n",
    "\n",
    "    This encoder mimics the behavior of sklearn's OrdinalEncoder but during the\n",
    "    fit, categories are not learned from the data. Instead, the user must provide\n",
    "    a list of unique categories. This is useful when the categories are known\n",
    "    beforehand and the data is large.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : np.ndarray\n",
    "        Unique categories in the data.\n",
    "    category_map_ : dict\n",
    "        Mapping of categories to integers.\n",
    "    inverse_category_map_ : dict\n",
    "        Mapping of integers to categories.\n",
    "    unknown_value : int | float, default=-1\n",
    "        Value to use for unknown categories.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, unknown_value: int | float = -1):\n",
    "\n",
    "        self.unknown_value = unknown_value\n",
    "        self.categories_ = None\n",
    "        self.category_map_ = None\n",
    "        self.inverse_category_map_ = None\n",
    "        \n",
    "    def fit(self, categories: list | np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Fit the encoder using the provided categories.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        categories : list | np.ndarray\n",
    "            Unique categories used to fit the encoder.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(categories, (list, np.ndarray)):\n",
    "            raise ValueError(\"Categories must be a list or numpy array.\")\n",
    "        if len(categories) == 0:\n",
    "            raise ValueError(\"Categories cannot be empty.\")\n",
    "\n",
    "        self.categories_ = np.sort(categories)\n",
    "        self.category_map_ = {category: idx for idx, category in enumerate(self.categories_)}\n",
    "        self.inverse_category_map_ = {idx: category for idx, category in enumerate(self.categories_)}\n",
    "    \n",
    "    def transform(self, X: np.ndarray | pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Transform the data to ordinal values using direct indexing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Input data to transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Transformed data with ordinal values.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.categories_ is None:\n",
    "            raise ValueError(\n",
    "                \"The encoder has not been fitted yet. Call 'fit' before 'transform'.\"\n",
    "            )\n",
    "        if not isinstance(X, (np.ndarray, pd.Series)):\n",
    "            raise ValueError(\"Input data must be a numpy array or pandas Series.\")\n",
    "        \n",
    "        encoded_data = pd.Series(X).map(self.category_map_)\n",
    "\n",
    "        return encoded_data\n",
    "\n",
    "    \n",
    "    def inverse_transform(self, X: np.ndarray | pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Inverse transform the encoded data back to original categories.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray | pd.Series\n",
    "            Encoded data to inverse transform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Inverse transformed data with original categories.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.categories_ is None:\n",
    "            raise ValueError(\n",
    "                \"The encoder has not been fitted yet. Call 'fit' before 'inverse_transform'.\"\n",
    "            )\n",
    "        if not isinstance(X, (np.ndarray, pd.Series)):\n",
    "            raise ValueError(\"Input data must be a numpy array or pandas Series.\")\n",
    "        \n",
    "        inverse_encoded_data = (\n",
    "            pd.Series(X)\n",
    "            .map(self.inverse_category_map_)\n",
    "        )\n",
    "\n",
    "        return inverse_encoded_data\n",
    "    \n",
    "\n",
    "# Create a large synthetic dataset of strings (categories)\n",
    "np.random.seed(42)\n",
    "categories = [f\"category_{i}\" for i in range(500)]\n",
    "data = np.repeat(categories, 1000)\n",
    "data_series = pd.Series(data)\n",
    "data_df = pd.DataFrame(data, columns=['y'])\n",
    "\n",
    "# Benchmark sklearn OrdinalEncoder\n",
    "start_time = time.time()\n",
    "sklearn_encoder = OrdinalEncoder()\n",
    "sklearn_encoded_data = sklearn_encoder.fit_transform(data_df)\n",
    "sklearn_time = time.time() - start_time\n",
    "print(f\"Sklearn OrdinalEncoder time: {sklearn_time:.4f} seconds\")\n",
    "\n",
    "# Benchmark FastOrdinalEncoder\n",
    "start_time = time.time()\n",
    "fast_encoder = FastOrdinalEncoder()\n",
    "fast_encoder.fit(categories)\n",
    "fast_encoded_data = fast_encoder.transform(data_series)\n",
    "fast_time = time.time() - start_time\n",
    "print(f\"FastOrdinalEncoder time: {fast_time:.4f} seconds\")\n",
    "\n",
    "# Check if the results are the same\n",
    "assert np.array_equal(sklearn_encoded_data.flatten(), fast_encoded_data)\n",
    "print(\"All encoders produced the same results.\")\n",
    "\n",
    "# check inverse transform\n",
    "assert np.array_equal(data, fast_encoder.inverse_transform(fast_encoded_data))\n",
    "print(\"Inverse transform works correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           category_0\n",
       "1           category_0\n",
       "2           category_0\n",
       "3           category_0\n",
       "4           category_0\n",
       "              ...     \n",
       "499995    category_499\n",
       "499996    category_499\n",
       "499997    category_499\n",
       "499998    category_499\n",
       "499999    category_499\n",
       "Length: 500000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [f\"category_{i}\" for i in range(500)]\n",
    "data = np.repeat(categories, 1000)\n",
    "data_series = pd.Series(data)\n",
    "data_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
